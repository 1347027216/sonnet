
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>sonnet.python.modules.rnn_core &#8212; sonnet git documentation</title>
    <link rel="stylesheet" href="../../../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="../../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for sonnet.python.modules.rnn_core</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2017 The Sonnet Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#    http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ============================================================================</span>

<span class="sd">&quot;&quot;&quot;Base class for TensorFlow Sonnet recurrent cores.</span>

<span class="sd">This file contains the Abstract Base Class for defining Recurrent Cores in</span>
<span class="sd">TensorFlow. A Recurrent Core is an object that holds the properties of other</span>
<span class="sd">`snt.Module`s and also satisfies the interface of any RNNCell in tensorflow.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">abc</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="c1"># Dependency imports</span>

<span class="kn">import</span> <span class="nn">six</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="k">import</span> <span class="n">xrange</span>  <span class="c1"># pylint: disable=redefined-builtin</span>
<span class="kn">from</span> <span class="nn">sonnet.python.modules</span> <span class="k">import</span> <span class="n">base</span>
<span class="kn">from</span> <span class="nn">sonnet.python.modules</span> <span class="k">import</span> <span class="n">basic</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">rnn_cell_impl</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util</span> <span class="k">import</span> <span class="n">nest</span>


<span class="k">def</span> <span class="nf">_single_learnable_state</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">state_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">learnable</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns an initial (maybe learnable) state.</span>

<span class="sd">  This function does not create any variable scopes, and it should be called</span>
<span class="sd">  from a Sonnet module. This function also makes sure that all the rows of its</span>
<span class="sd">  `state` argument have the same value.</span>

<span class="sd">  Args:</span>
<span class="sd">    state: initial value of the initial state. It should be a tensor of at least</span>
<span class="sd">      two dimensions, of which the first dimension corresponds to the</span>
<span class="sd">      batch_size dimension. All rows of such tensor should have the same value.</span>
<span class="sd">    state_id: integer that uniquely identifies this state.</span>
<span class="sd">    learnable: boolean that indicates whether the state is learnable.</span>

<span class="sd">  Returns:</span>
<span class="sd">    The initial learnable state `Tensor`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">unpacked_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
  <span class="c1"># Assert that all rows have the same values.</span>
  <span class="n">assert_rows_equal</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">assert_equal</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">unpacked_state</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                       <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">unpacked_state</span><span class="p">]</span>

  <span class="c1"># We wish to have all the graph assertions in the graph&#39;s critical path,</span>
  <span class="c1"># so we include them even if the initial state is left unmodified (i.e. when</span>
  <span class="c1"># the state is not learnable).</span>
  <span class="c1"># Note: All these assertions will be run every time that data flows</span>
  <span class="c1"># through the graph. At that point, the control_dependencies context manager</span>
  <span class="c1"># makes sure that such assertions are run, and will raise an exception if any</span>
  <span class="c1"># fails.</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">assert_rows_equal</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">learnable</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">state</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">state_shape</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
      <span class="n">state_shape</span><span class="o">.</span><span class="n">assert_is_fully_defined</span><span class="p">()</span>
      <span class="n">state_shape_list</span> <span class="o">=</span> <span class="n">state_shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
      <span class="n">batch_size</span><span class="p">,</span> <span class="n">trailing_shape</span> <span class="o">=</span> <span class="n">state_shape_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">state_shape_list</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

      <span class="n">initial_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">unpacked_state</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">trailing_shape</span><span class="p">)</span>
      <span class="n">initial_state_variable</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
          <span class="s2">&quot;initial_state_</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">state_id</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">initial_value</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
          <span class="n">initializer</span><span class="o">=</span><span class="n">initial_value</span><span class="p">)</span>

      <span class="n">trailing_size_repeat</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">trailing_shape</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">initial_state_variable</span><span class="p">,</span>
                     <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="n">batch_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">trailing_size_repeat</span><span class="p">))</span>


<div class="viewcode-block" id="trainable_initial_state"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.rnn_core.trainable_initial_state">[docs]</a><span class="k">def</span> <span class="nf">trainable_initial_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">state_size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">initializers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">regularizers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Creates an initial state consisting of trainable variables.</span>

<span class="sd">  The trainable variables are created with the same shapes as the elements of</span>
<span class="sd">  `state_size` and are tiled to produce an initial state.</span>

<span class="sd">  Args:</span>
<span class="sd">    batch_size: An int, or scalar int32 Tensor representing the batch size.</span>
<span class="sd">    state_size: A `TensorShape` or nested tuple of `TensorShape`s to use for the</span>
<span class="sd">        shape of the trainable variables.</span>
<span class="sd">    dtype: The data type used to create the variables and thus initial state.</span>
<span class="sd">    initializers: An optional container of the same structure as `state_size`</span>
<span class="sd">        containing initializers for the variables.</span>
<span class="sd">    regularizers: An optional container of the same structure as `state_size`</span>
<span class="sd">        containing regularizers for the variables.</span>
<span class="sd">    name: optional string used to prefix the initial state variable names.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` or nested tuple of `Tensor`s with the same size and structure</span>
<span class="sd">    as `state_size`, where each `Tensor` is a tiled trainable `Variable`.</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError: if the user passes initializers that are not functions.</span>
<span class="sd">    ValueError: if the user passes regularizers that are not functions.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">flat_state_size</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">state_size</span><span class="p">)</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">initializers</span><span class="p">:</span>
    <span class="n">flat_initializer</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">flat_state_size</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">nest</span><span class="o">.</span><span class="n">assert_same_structure</span><span class="p">(</span><span class="n">initializers</span><span class="p">,</span> <span class="n">state_size</span><span class="p">)</span>
    <span class="n">flat_initializer</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">initializers</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">([</span><span class="n">callable</span><span class="p">(</span><span class="n">init</span><span class="p">)</span> <span class="k">for</span> <span class="n">init</span> <span class="ow">in</span> <span class="n">flat_initializer</span><span class="p">]):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not all the passed initializers are callable objects.&quot;</span><span class="p">)</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">regularizers</span><span class="p">:</span>
    <span class="n">flat_regularizer</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">({}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">flat_state_size</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">nest</span><span class="o">.</span><span class="n">assert_same_structure</span><span class="p">(</span><span class="n">regularizers</span><span class="p">,</span> <span class="n">state_size</span><span class="p">)</span>
    <span class="n">flat_regularizer</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">regularizers</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">([</span><span class="n">callable</span><span class="p">(</span><span class="n">regularizer</span><span class="p">)</span> <span class="k">for</span> <span class="n">regularizer</span> <span class="ow">in</span> <span class="n">flat_regularizer</span><span class="p">]):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not all the passed regularizers are callable objects.&quot;</span><span class="p">)</span>

  <span class="c1"># Produce names for the variables. In the case of a tuple or nested tuple,</span>
  <span class="c1"># this is just a sequence of numbers, but for a flat `namedtuple`, we use</span>
  <span class="c1"># the field names. NOTE: this could be extended to nested `namedtuple`s,</span>
  <span class="c1"># but for now that&#39;s extra complexity that&#39;s not used anywhere.</span>
  <span class="n">name_prefix</span> <span class="o">=</span> <span class="n">name</span> <span class="ow">or</span> <span class="s2">&quot;initial_state&quot;</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">name_suffixes</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">state_size</span><span class="o">.</span><span class="n">_fields</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">flat_state_size</span><span class="p">))]</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">AttributeError</span><span class="p">,</span> <span class="ne">IndexError</span><span class="p">):</span>
    <span class="n">name_suffixes</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">flat_state_size</span><span class="p">))</span>

  <span class="n">flat_initial_state</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">for</span> <span class="n">name_suffix</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">init</span><span class="p">,</span> <span class="n">regularizer</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
      <span class="n">name_suffixes</span><span class="p">,</span> <span class="n">flat_state_size</span><span class="p">,</span> <span class="n">flat_initializer</span><span class="p">,</span> <span class="n">flat_regularizer</span><span class="p">):</span>
    <span class="n">shape_with_batch_dim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>

    <span class="n">variable_name</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name_prefix</span><span class="p">,</span> <span class="n">name_suffix</span><span class="p">)</span>
    <span class="n">initial_state_module</span> <span class="o">=</span> <span class="n">basic</span><span class="o">.</span><span class="n">TrainableVariable</span><span class="p">(</span>
        <span class="n">shape_with_batch_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">initializers</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;w&quot;</span><span class="p">:</span> <span class="n">init</span><span class="p">},</span>
        <span class="n">regularizers</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;w&quot;</span><span class="p">:</span> <span class="n">regularizer</span><span class="p">},</span> <span class="n">name</span><span class="o">=</span><span class="n">variable_name</span><span class="p">)</span>
    <span class="n">initial_state_variable</span> <span class="o">=</span> <span class="n">initial_state_module</span><span class="p">()</span>

    <span class="n">tiled_name</span> <span class="o">=</span> <span class="s2">&quot;state_</span><span class="si">{}</span><span class="s2">_tiled&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name_suffix</span><span class="p">)</span>

    <span class="n">initial_state_variable_dims</span> <span class="o">=</span> <span class="n">initial_state_variable</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span>
    <span class="n">tile_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">initial_state_variable_dims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">flat_initial_state</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">initial_state_variable</span><span class="p">,</span> <span class="n">tile_dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">tiled_name</span><span class="p">))</span>

  <span class="k">return</span> <span class="n">nest</span><span class="o">.</span><span class="n">pack_sequence_as</span><span class="p">(</span><span class="n">structure</span><span class="o">=</span><span class="n">state_size</span><span class="p">,</span>
                               <span class="n">flat_sequence</span><span class="o">=</span><span class="n">flat_initial_state</span><span class="p">)</span></div>


<div class="viewcode-block" id="RNNCore"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.rnn_core.RNNCore">[docs]</a><span class="nd">@six</span><span class="o">.</span><span class="n">add_metaclass</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABCMeta</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">RNNCore</span><span class="p">(</span><span class="n">base</span><span class="o">.</span><span class="n">AbstractModule</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Superclass for Recurrent Neural Network Cores.</span>

<span class="sd">  This class defines the basic functionality that every core should implement,</span>
<span class="sd">  mainly the `initial_state` method which will return an example of their</span>
<span class="sd">  initial state.</span>
<span class="sd">  It also inherits from the two interfaces it should be compatible with, which</span>
<span class="sd">  are `snt.Module` and `tf.contrib.rnn.RNNCell`.</span>

<span class="sd">  As with any other `snt.Module` any subclass must implement a `_build` method</span>
<span class="sd">  that constructs the graph that corresponds to a core. Such a `_build` method</span>
<span class="sd">  should always have the same interface, which is the following:</span>

<span class="sd">      output, next_state = self._build(input, prev_state)</span>

<span class="sd">  where output, next_state, input, and prev_state are arbitrarily nested</span>
<span class="sd">  tensors. Such structures can be defined according to the following</span>
<span class="sd">  grammar:</span>

<span class="sd">      element = tuple(element*) | list(element*) | tf.Tensor</span>

<span class="sd">  This class is to be used with tensorflow containers such as `rnn` in</span>
<span class="sd">  tensorflow.python.ops.rnn. These containers only accept</span>
<span class="sd">  `tf.contrib.rnn.RNNCell` objects, hence the need to comply with its interface.</span>
<span class="sd">  This way, all the RNNCores should expose a `state_size` and `output_size`</span>
<span class="sd">  properties.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">__metaclass__</span> <span class="o">=</span> <span class="n">abc</span><span class="o">.</span><span class="n">ABCMeta</span>

  <span class="k">def</span> <span class="nf">_initial_state_scope</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Defines the name scope of the initial_state ops.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">name</span> <span class="k">if</span> <span class="n">name</span> <span class="k">else</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">_initial_state&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">scope_name</span>

<div class="viewcode-block" id="RNNCore.initial_state"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.rnn_core.RNNCore.initial_state">[docs]</a>  <span class="k">def</span> <span class="nf">initial_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">trainable_initializers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable_regularizers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">unused_kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Builds the default start state for an RNNCore.</span>

<span class="sd">    Args:</span>
<span class="sd">      batch_size: An int, or scalar int32 Tensor representing the batch size.</span>
<span class="sd">      dtype: The data type to use for the state.</span>
<span class="sd">      trainable: Boolean that indicates whether to learn the initial state.</span>
<span class="sd">        Note that intializers and regularizers will be ignored if</span>
<span class="sd">        `trainable=False`.</span>
<span class="sd">      trainable_initializers: An initializer function or nested structure of</span>
<span class="sd">          functions with same structure as the `state_size` property of the</span>
<span class="sd">          core, to be used as initializers of the initial state variable.</span>
<span class="sd">      trainable_regularizers: Optional regularizer function or nested structure</span>
<span class="sd">        of functions with the same structure as the `state_size` property of the</span>
<span class="sd">        core, to be used as regularizers of the initial state variable. As a</span>
<span class="sd">        default, no regularizers are used. A regularizer should be a function</span>
<span class="sd">        that takes a single `Tensor` as an input and returns a scalar `Tensor`</span>
<span class="sd">        output, e.g. the L1 and L2 regularizers in `tf.contrib.layers`.</span>
<span class="sd">      name: Optional string used to prefix the initial state variable names, in</span>
<span class="sd">          the case of a trainable initial state. If not provided, defaults to</span>
<span class="sd">          the name of the module.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tensor or nested tuple of tensors with same structure and shape as the</span>
<span class="sd">      `state_size` property of the core.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: if the user passes initializers that are not functions.</span>
<span class="sd">      ValueError: if the user passes regularizers that are not functions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_initial_state_scope</span><span class="p">(</span><span class="n">name</span><span class="p">)):</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">trainable</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">trainable_initial_state</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span>
            <span class="n">initializers</span><span class="o">=</span><span class="n">trainable_initializers</span><span class="p">,</span>
            <span class="n">regularizers</span><span class="o">=</span><span class="n">trainable_regularizers</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_initial_state_scope</span><span class="p">(</span><span class="n">name</span><span class="p">))</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">state_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;size(s) of state(s) used by this cell.</span>

<span class="sd">    It can be represented by an Integer, a TensorShape or a tuple of Integers</span>
<span class="sd">    or TensorShapes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Abstract method&quot;</span><span class="p">)</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">output_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Integer or TensorShape: size of outputs produced by this cell.&quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Abstract method&quot;</span><span class="p">)</span>

<div class="viewcode-block" id="RNNCore.zero_state"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.rnn_core.RNNCore.zero_state">[docs]</a>  <span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return zero-filled state tensor(s).</span>

<span class="sd">    Args:</span>
<span class="sd">      batch_size: int, float, or unit Tensor representing the batch size.</span>
<span class="sd">      dtype: the data type to use for the state.</span>

<span class="sd">    Returns:</span>
<span class="sd">      If `state_size` is an int or TensorShape, then the return value is a</span>
<span class="sd">      `N-D` tensor of shape `[batch_size x state_size]` filled with zeros.</span>

<span class="sd">      If `state_size` is a nested list or tuple, then the return value is</span>
<span class="sd">      a nested list or tuple (of the same structure) of `2-D` tensors with</span>
<span class="sd">      the shapes `[batch_size x s]` for each s in `state_size`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Keep scope for backwards compatibility.</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">&quot;ZeroState&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">]):</span>
      <span class="k">return</span> <span class="n">rnn_cell_impl</span><span class="o">.</span><span class="n">_zero_state_tensors</span><span class="p">(</span>  <span class="c1"># pylint: disable=protected-access</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">state_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="TrainableInitialState"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.rnn_core.TrainableInitialState">[docs]</a><span class="k">class</span> <span class="nc">TrainableInitialState</span><span class="p">(</span><span class="n">base</span><span class="o">.</span><span class="n">AbstractModule</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Helper Module that creates a learnable initial state for an RNNCore.</span>

<span class="sd">  This class receives an example (possibly nested) initial state of an RNNCore,</span>
<span class="sd">  and returns a state that has the same shape, structure, and values, but is</span>
<span class="sd">  trainable. Additionally, the user may specify a boolean mask that</span>
<span class="sd">  indicates which parts of the initial state should be trainable.</span>

<span class="sd">  This allows users to train an unrolled RNNCore with a learnable initial state</span>
<span class="sd">  in the following way:</span>

<span class="sd">      core = ... # Any RNNCore module object.</span>
<span class="sd">      initial_state = core.initial_state(batch_size, dtype)</span>
<span class="sd">      trainable_initial_state = snt.TrainableInitialState(initial_state)()</span>
<span class="sd">      output, final_state = tf.nn.dynamic_rnn(</span>
<span class="sd">          core, input_sequence, initial_state=trainable_initial_state)</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;trainable_initial_state&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs the Module that introduces a trainable state in the graph.</span>

<span class="sd">    It receives an initial state that will be used as the initial values for the</span>
<span class="sd">    trainable variables that the module contains, and optionally a mask that</span>
<span class="sd">    indicates the parts of the initial state that should be learnable.</span>

<span class="sd">    Args:</span>
<span class="sd">      initial_state: tensor or arbitrarily nested iterables of tensors.</span>
<span class="sd">      mask: optional boolean mask. It should have the same nested structure as</span>
<span class="sd">       the given initial_state.</span>
<span class="sd">      name: module name.</span>

<span class="sd">    Raises:</span>
<span class="sd">      TypeError: if mask is not a list of booleans or None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">TrainableInitialState</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="c1"># Since python 2.7, DeprecationWarning is ignored by default.</span>
    <span class="c1"># Turn on the warning:</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;always&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Use the trainable flag in initial_state instead.&quot;</span><span class="p">,</span>
                  <span class="ne">DeprecationWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">flat_mask</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">([</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">flat_mask</span><span class="p">]):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Mask should be None or a list of boolean values.&quot;</span><span class="p">)</span>
      <span class="n">nest</span><span class="o">.</span><span class="n">assert_same_structure</span><span class="p">(</span><span class="n">initial_state</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span> <span class="o">=</span> <span class="n">mask</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_initial_state</span> <span class="o">=</span> <span class="n">initial_state</span>

  <span class="k">def</span> <span class="nf">_build</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Connects the module to the graph.</span>

<span class="sd">    Returns:</span>
<span class="sd">      The learnable state, which has the same type, structure and shape as</span>
<span class="sd">        the `initial_state` passed to the constructor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">flat_initial_state</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_initial_state</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">flat_mask</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="p">)</span>
      <span class="n">flat_learnable_state</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">_single_learnable_state</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">state_id</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">learnable</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
          <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">flat_initial_state</span><span class="p">,</span> <span class="n">flat_mask</span><span class="p">))]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">flat_learnable_state</span> <span class="o">=</span> <span class="p">[</span><span class="n">_single_learnable_state</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">state_id</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
                              <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">state</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">flat_initial_state</span><span class="p">)]</span>

    <span class="k">return</span> <span class="n">nest</span><span class="o">.</span><span class="n">pack_sequence_as</span><span class="p">(</span><span class="n">structure</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_initial_state</span><span class="p">,</span>
                                 <span class="n">flat_sequence</span><span class="o">=</span><span class="n">flat_learnable_state</span><span class="p">)</span></div>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../index.html">Documentation overview</a><ul>
  <li><a href="../../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Sonnet Authors.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.7.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
    </div>

    

    
  </body>
</html>