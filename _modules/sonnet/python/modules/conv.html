
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>sonnet.python.modules.conv &#8212; sonnet git documentation</title>
    <link rel="stylesheet" href="../../../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for sonnet.python.modules.conv</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2017 The Sonnet Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#    http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ============================================================================</span>

<span class="sd">&quot;&quot;&quot;Implementation of convolutional Sonnet modules.</span>

<span class="sd">Classes defining convolutional operations, inheriting from `snt.Module`, with</span>
<span class="sd">easy weight sharing.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numbers</span>

<span class="c1"># Dependency imports</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sonnet.python.modules</span> <span class="k">import</span> <span class="n">base</span>
<span class="kn">from</span> <span class="nn">sonnet.python.modules</span> <span class="k">import</span> <span class="n">util</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>


<span class="c1"># Strings for TensorFlow convolution padding modes. See the following</span>
<span class="c1"># documentation for an explanation of VALID versus SAME:</span>
<span class="c1"># https://www.tensorflow.org/api_guides/python/nn#Convolution</span>
<span class="n">SAME</span> <span class="o">=</span> <span class="s2">&quot;SAME&quot;</span>
<span class="n">VALID</span> <span class="o">=</span> <span class="s2">&quot;VALID&quot;</span>
<span class="n">ALLOWED_PADDINGS</span> <span class="o">=</span> <span class="p">{</span><span class="n">SAME</span><span class="p">,</span> <span class="n">VALID</span><span class="p">}</span>

<span class="n">DATA_FORMAT_NCW</span> <span class="o">=</span> <span class="s2">&quot;NCW&quot;</span>
<span class="n">DATA_FORMAT_NWC</span> <span class="o">=</span> <span class="s2">&quot;NWC&quot;</span>
<span class="n">SUPPORTED_1D_DATA_FORMATS</span> <span class="o">=</span> <span class="p">{</span><span class="n">DATA_FORMAT_NCW</span><span class="p">,</span> <span class="n">DATA_FORMAT_NWC</span><span class="p">}</span>

<span class="n">DATA_FORMAT_NCHW</span> <span class="o">=</span> <span class="s2">&quot;NCHW&quot;</span>
<span class="n">DATA_FORMAT_NHWC</span> <span class="o">=</span> <span class="s2">&quot;NHWC&quot;</span>
<span class="n">SUPPORTED_2D_DATA_FORMATS</span> <span class="o">=</span> <span class="p">{</span><span class="n">DATA_FORMAT_NCHW</span><span class="p">,</span> <span class="n">DATA_FORMAT_NHWC</span><span class="p">}</span>

<span class="n">DATA_FORMAT_NDHWC</span> <span class="o">=</span> <span class="s2">&quot;NDHWC&quot;</span>
<span class="n">DATA_FORMAT_NCDHW</span> <span class="o">=</span> <span class="s2">&quot;NCDHW&quot;</span>
<span class="n">SUPPORTED_3D_DATA_FORMATS</span> <span class="o">=</span> <span class="p">{</span><span class="n">DATA_FORMAT_NDHWC</span><span class="p">,</span> <span class="n">DATA_FORMAT_NCDHW</span><span class="p">}</span>


<span class="k">def</span> <span class="nf">_default_transpose_size</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">padding</span><span class="o">=</span><span class="n">SAME</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns default (maximal) output shape for a transpose convolution.</span>

<span class="sd">  In general, there are multiple possible output shapes that a transpose</span>
<span class="sd">  convolution with a given `input_shape` can map to. This function returns the</span>
<span class="sd">  output shape which evenly divides the stride to produce the input shape in</span>
<span class="sd">  a forward convolution, i.e. the maximal valid output shape with the given</span>
<span class="sd">  configuration:</span>

<span class="sd">  if the padding type is SAME then:  output_shape = input_shape * stride</span>
<span class="sd">  if the padding type is VALID then: output_shape = input_shape * stride +</span>
<span class="sd">                                                    kernel_shape - 1</span>

<span class="sd">  See the following documentation for an explanation of VALID versus SAME</span>
<span class="sd">  padding modes:</span>
<span class="sd">  https://www.tensorflow.org/versions/r0.8/api_docs/python/nn.html#convolution</span>

<span class="sd">  Args:</span>
<span class="sd">    input_shape: Sequence of sizes of each dimension of the input, excluding</span>
<span class="sd">      batch and channel dimensions.</span>
<span class="sd">    stride: Sequence or integer of kernel strides, excluding batch and channel</span>
<span class="sd">      dimension strides.</span>
<span class="sd">    kernel_shape: Sequence or integer of kernel sizes.</span>
<span class="sd">    padding: Padding algorithm, either `snt.SAME` or `snt.VALID`.</span>

<span class="sd">  Returns:</span>
<span class="sd">    output_shape: A tuple of sizes for a transposed convolution that divide</span>
<span class="sd">      evenly with the given strides, kernel shapes, and padding algorithm.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">input_shape</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;input_shape is None; if using Sonnet, are you sure you &quot;</span>
                    <span class="s2">&quot;have connected the module to inputs?&quot;</span><span class="p">)</span>
  <span class="n">input_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
  <span class="n">stride</span> <span class="o">=</span> <span class="n">_fill_and_verify_parameter_shape</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="s2">&quot;stride&quot;</span><span class="p">)</span>
  <span class="n">padding</span> <span class="o">=</span> <span class="n">_verify_padding</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>

  <span class="n">output_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">y</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">stride</span><span class="p">))</span>

  <span class="k">if</span> <span class="n">padding</span> <span class="o">==</span> <span class="n">VALID</span><span class="p">:</span>
    <span class="n">kernel_shape</span> <span class="o">=</span> <span class="n">_fill_and_verify_parameter_shape</span><span class="p">(</span><span class="n">kernel_shape</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span>
                                                    <span class="s2">&quot;kernel&quot;</span><span class="p">)</span>
    <span class="n">output_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">output_shape</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">))</span>

  <span class="k">return</span> <span class="n">output_shape</span>


<span class="k">def</span> <span class="nf">_fill_shape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Converts a dimension to a tuple of dimensions of a given size.</span>

<span class="sd">  This is used to allow shorthand notation for various configuration parameters.</span>
<span class="sd">  A user can provide either, for example, `2` or `[2, 2]` as a kernel shape, and</span>
<span class="sd">  this function returns `(2, 2)` in both cases. Passing `[1, 2]` will return</span>
<span class="sd">  `(1, 2)`.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: An integer, tf.Dimension, or an iterable of them.</span>
<span class="sd">    n: An integer, the size of the desired output list</span>

<span class="sd">  Returns:</span>
<span class="sd">    If `x` is an integer, a tuple of size `n` containing `n` copies of `x`.</span>
<span class="sd">    If `x` is an iterable of integers or tf.Dimension of size `n`, it returns</span>
<span class="sd">      `tuple(x)`.</span>

<span class="sd">  Raises:</span>
<span class="sd">    TypeError: If n is not a positive integer;</span>
<span class="sd">      or if x is neither integer nor an iterable of size n.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span> <span class="ow">or</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;n must be a positive integer&quot;</span><span class="p">)</span>

  <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Dimension</span><span class="p">))</span> <span class="ow">and</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">*</span> <span class="n">n</span>

  <span class="k">try</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="n">v</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">x</span><span class="p">):</span>
      <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
    <span class="k">pass</span>

  <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;x is </span><span class="si">{}</span><span class="s2">, must be either a positive integer &quot;</span>
                  <span class="s2">&quot;or an iterable of positive integers of size </span><span class="si">{}</span><span class="s2">&quot;</span>
                  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_fill_and_verify_parameter_shape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">parameter_label</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Expands x if necessary into a `n`-D kernel shape and reports errors.&quot;&quot;&quot;</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">_fill_shape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
  <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">raise</span> <span class="n">base</span><span class="o">.</span><span class="n">IncompatibleShapeError</span><span class="p">(</span><span class="s2">&quot;Invalid &quot;</span> <span class="o">+</span> <span class="n">parameter_label</span> <span class="o">+</span> <span class="s2">&quot; shape: &quot;</span>
                                      <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_verify_padding</span><span class="p">(</span><span class="n">padding</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Verifies that the provided padding is supported. Returns padding.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">padding</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ALLOWED_PADDINGS</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="s2">&quot;Padding must be member of &#39;</span><span class="si">{}</span><span class="s2">&#39;, not </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">ALLOWED_PADDINGS</span><span class="p">,</span> <span class="n">padding</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">padding</span>


<span class="k">def</span> <span class="nf">_fill_and_one_pad_stride</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="n">DATA_FORMAT_NHWC</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Expands the provided stride to size n and pads it with 1s.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
      <span class="nb">isinstance</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">collections</span><span class="o">.</span><span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">n</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">data_format</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;NC&quot;</span><span class="p">):</span>
      <span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">_fill_shape</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">data_format</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">data_format</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;C&quot;</span><span class="p">):</span>
      <span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">_fill_shape</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="s2">&quot;Invalid data_format </span><span class="si">{:s}</span><span class="s2">. Must start with N and have a channel dim &quot;</span>
          <span class="s2">&quot;either follow the N dim or come at the end&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data_format</span><span class="p">))</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">collections</span><span class="o">.</span><span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span> <span class="o">==</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">2</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">stride</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">raise</span> <span class="n">base</span><span class="o">.</span><span class="n">IncompatibleShapeError</span><span class="p">(</span>
        <span class="s2">&quot;stride is </span><span class="si">{}</span><span class="s2"> (</span><span class="si">{}</span><span class="s2">), must be either a positive integer or an iterable of&quot;</span>
        <span class="s2">&quot; positive integers of size </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">stride</span><span class="p">),</span> <span class="n">n</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_verify_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">channel_index</span><span class="p">,</span> <span class="n">data_format</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Verifies `inputs` is semantically correct.</span>

<span class="sd">  Args:</span>
<span class="sd">    inputs: An input tensor provided by the user.</span>
<span class="sd">    channel_index: The index of the channel dimension.</span>
<span class="sd">    data_format: The format of the data in `inputs`.</span>

<span class="sd">  Raises:</span>
<span class="sd">    base.IncompatibleShapeError: If the shape of `inputs` doesn&#39;t match</span>
<span class="sd">      `data_format`.</span>
<span class="sd">    base.UnderspecifiedError: If the channel dimension of `inputs` isn&#39;t</span>
<span class="sd">      defined.</span>
<span class="sd">    TypeError: If input Tensor dtype is not compatible with either</span>
<span class="sd">      `tf.float16`, `tf.bfloat16` or `tf.float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># Check shape.</span>
  <span class="n">input_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_format</span><span class="p">):</span>
    <span class="k">raise</span> <span class="n">base</span><span class="o">.</span><span class="n">IncompatibleShapeError</span><span class="p">((</span>
        <span class="s2">&quot;Input Tensor must have rank </span><span class="si">{}</span><span class="s2"> corresponding to &quot;</span>
        <span class="s2">&quot;data_format </span><span class="si">{}</span><span class="s2">, but instead was </span><span class="si">{}</span><span class="s2"> of rank </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">data_format</span><span class="p">),</span> <span class="n">data_format</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)))</span>

  <span class="c1"># Check type.</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float16</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="ow">or</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">bfloat16</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="ow">or</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Input must have dtype tf.float16, tf.bfloat16 or tf.float32, &quot;</span>
        <span class="s2">&quot;but dtype was </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

  <span class="c1"># Check channel dim.</span>
  <span class="n">input_channels</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="n">channel_index</span><span class="p">]</span>
  <span class="k">if</span> <span class="n">input_channels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">raise</span> <span class="n">base</span><span class="o">.</span><span class="n">UnderspecifiedError</span><span class="p">(</span>
        <span class="s2">&quot;Number of input channels must be known at module build time&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="create_weight_initializer"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.create_weight_initializer">[docs]</a><span class="k">def</span> <span class="nf">create_weight_initializer</span><span class="p">(</span><span class="n">fan_in_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns a default initializer for the weights of a convolutional module.&quot;&quot;&quot;</span>
  <span class="n">stddev</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">fan_in_shape</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span><span class="n">stddev</span><span class="o">=</span><span class="n">stddev</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="create_bias_initializer"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.create_bias_initializer">[docs]</a><span class="k">def</span> <span class="nf">create_bias_initializer</span><span class="p">(</span><span class="n">unused_bias_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns a default initializer for the biases of a convolutional module.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_find_channel_index</span><span class="p">(</span><span class="n">data_format</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns the index of the channel dimension.</span>

<span class="sd">  Args:</span>
<span class="sd">    data_format: A string of characters corresponding to Tensor dimensionality.</span>

<span class="sd">  Returns:</span>
<span class="sd">    channel_index: An integer indicating the channel dimension.</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError: If no channel dimension was found.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_format</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">c</span> <span class="o">==</span> <span class="s2">&quot;C&quot;</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">i</span>
  <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;data_format requires a channel dimension. Got: </span><span class="si">{}</span><span class="s2">&quot;</span>
                   <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data_format</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_apply_bias</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">channel_index</span><span class="p">,</span> <span class="n">data_format</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span>
                <span class="n">initializers</span><span class="p">,</span> <span class="n">partitioners</span><span class="p">,</span> <span class="n">regularizers</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Initialize and apply a bias to the outputs.</span>

<span class="sd">  Figures out the shape of the bias vector, initialize it, and applies it.</span>

<span class="sd">  Args:</span>
<span class="sd">    inputs: A Tensor of shape `data_format`.</span>
<span class="sd">    outputs: A Tensor of shape `data_format`.</span>
<span class="sd">    channel_index: The index of the channel dimension in `inputs`.</span>
<span class="sd">    data_format: Format of `inputs`.</span>
<span class="sd">    output_channels: Channel dimensionality for `outputs`.</span>
<span class="sd">    initializers: Optional dict containing ops to initialize the biases</span>
<span class="sd">      (with key &#39;b&#39;).</span>
<span class="sd">    partitioners: Optional dict containing partitioners to partition the</span>
<span class="sd">      biases (with key &#39;b&#39;).</span>
<span class="sd">    regularizers: Optional dict containing regularizers for the biases</span>
<span class="sd">      (with key &#39;b&#39;).</span>

<span class="sd">  Returns:</span>
<span class="sd">    b: The constructed bias variable.</span>
<span class="sd">    outputs: The `outputs` argument that has had a bias applied.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">bias_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">output_channels</span><span class="p">,)</span>
  <span class="k">if</span> <span class="s2">&quot;b&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">initializers</span><span class="p">:</span>
    <span class="n">initializers</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">create_bias_initializer</span><span class="p">(</span><span class="n">bias_shape</span><span class="p">,</span>
                                                <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span>
                      <span class="n">shape</span><span class="o">=</span><span class="n">bias_shape</span><span class="p">,</span>
                      <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                      <span class="n">initializer</span><span class="o">=</span><span class="n">initializers</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">],</span>
                      <span class="n">partitioner</span><span class="o">=</span><span class="n">partitioners</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                      <span class="n">regularizer</span><span class="o">=</span><span class="n">regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>

  <span class="c1"># tf.nn.bias_add only supports 2 data formats.</span>
  <span class="k">if</span> <span class="n">data_format</span> <span class="ow">in</span> <span class="p">(</span><span class="n">DATA_FORMAT_NHWC</span><span class="p">,</span> <span class="n">DATA_FORMAT_NCHW</span><span class="p">):</span>
    <span class="c1"># Supported as-is.</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="c1"># Create our own bias vector.</span>
    <span class="n">bias_correct_dim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_format</span><span class="p">)</span>
    <span class="n">bias_correct_dim</span><span class="p">[</span><span class="n">channel_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_channels</span>
    <span class="n">outputs</span> <span class="o">+=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">bias_correct_dim</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">b</span><span class="p">,</span> <span class="n">outputs</span>


<span class="k">class</span> <span class="nc">_ConvND</span><span class="p">(</span><span class="n">base</span><span class="o">.</span><span class="n">AbstractModule</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;N-dimensional convolution and dilated convolution module, including bias.</span>

<span class="sd">  This acts as a light wrapper around the TensorFlow ops `tf.nn.convolution`</span>
<span class="sd">  abstracting away variable creation and sharing.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">padding</span><span class="o">=</span><span class="n">SAME</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">initializers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">partitioners</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regularizers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">data_format</span><span class="o">=</span><span class="n">DATA_FORMAT_NHWC</span><span class="p">,</span>
               <span class="n">custom_getter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv_nd&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a _ConvND module.</span>

<span class="sd">    See the following documentation for an explanation of VALID versus SAME</span>
<span class="sd">    padding modes:</span>
<span class="sd">    https://www.tensorflow.org/api_guides/python/nn#Convolution</span>

<span class="sd">    Args:</span>
<span class="sd">      output_channels: Number of output channels. `output_channels` can be</span>
<span class="sd">          either a number or a callable. In the latter case, since the function</span>
<span class="sd">          invocation is deferred to graph construction time, the user must only</span>
<span class="sd">          ensure that output_channels can be called, returning an integer,</span>
<span class="sd">          when `build` is called.</span>
<span class="sd">      kernel_shape: Sequence of kernel sizes (up to size N), or an integer.</span>
<span class="sd">          `kernel_shape` will be expanded to define a kernel size in all</span>
<span class="sd">          dimensions.</span>
<span class="sd">      stride: Sequence of strides (up to size N), or an integer.</span>
<span class="sd">          `stride` will be expanded to define stride in all dimensions.</span>
<span class="sd">      rate: Sequence of dilation rates (of size N), or integer that is used to</span>
<span class="sd">          define dilation rate in all dimensions. 1 corresponds to standard ND</span>
<span class="sd">          convolution, `rate &gt; 1` corresponds to dilated convolution. Cannot be</span>
<span class="sd">          &gt; 1 if any of `stride` is also &gt; 1.</span>
<span class="sd">      padding: Padding algorithm, either `snt.SAME` or `snt.VALID`.</span>
<span class="sd">      use_bias: Whether to include bias parameters. Default `True`.</span>
<span class="sd">      initializers: Optional dict containing ops to initialize the filters (with</span>
<span class="sd">          key &#39;w&#39;) or biases (with key &#39;b&#39;). The default initializer for the</span>
<span class="sd">          weights is a truncated normal initializer, which is commonly used</span>
<span class="sd">          when the inputs are zero centered (see</span>
<span class="sd">          https://arxiv.org/pdf/1502.03167v3.pdf). The default initializer for</span>
<span class="sd">          the bias is a zero initializer.</span>
<span class="sd">      partitioners: Optional dict containing partitioners to partition</span>
<span class="sd">          weights (with key &#39;w&#39;) or biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          partitioners are used.</span>
<span class="sd">      regularizers: Optional dict containing regularizers for the filters</span>
<span class="sd">          (with key &#39;w&#39;) and the biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          regularizers are used. A regularizer should be a function that takes</span>
<span class="sd">          a single `Tensor` as an input and returns a scalar `Tensor` output,</span>
<span class="sd">          e.g. the L1 and L2 regularizers in `tf.contrib.layers`.</span>
<span class="sd">      mask: A convertible to a ND tensor which is multiplied</span>
<span class="sd">          component-wise with the weights (Optional).</span>
<span class="sd">      data_format: The data format of the input.</span>
<span class="sd">      custom_getter: Callable or dictionary of callables to use as</span>
<span class="sd">          custom getters inside the module. If a dictionary, the keys</span>
<span class="sd">          correspond to regexes to match variable names. See the</span>
<span class="sd">          `tf.get_variable` documentation for information about the</span>
<span class="sd">          custom_getter API.</span>
<span class="sd">      name: Name of the module.</span>

<span class="sd">    Raises:</span>
<span class="sd">      base.IncompatibleShapeError: If the given kernel shape is not an integer;</span>
<span class="sd">          or if the given kernel shape is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given stride is not an integer; or if</span>
<span class="sd">          the given stride is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given rate is not an integer; or if</span>
<span class="sd">          the given rate is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If a mask is a TensorFlow Tensor with</span>
<span class="sd">          a not fully defined shape.</span>
<span class="sd">      base.NotSupportedError: If rate in any dimension and the stride in any</span>
<span class="sd">          dimension are simultaneously &gt; 1.</span>
<span class="sd">      ValueError: If the given padding is not `snt.VALID` or `snt.SAME`.</span>
<span class="sd">      KeyError: If `initializers`, `partitioners` or `regularizers` contain any</span>
<span class="sd">          keys other than &#39;w&#39; or &#39;b&#39;.</span>
<span class="sd">      TypeError: If any of the given initializers, partitioners or regularizers</span>
<span class="sd">          are not callable.</span>
<span class="sd">      TypeError: If mask is given and it is not convertible to a Tensor.</span>
<span class="sd">      ValueError: If the passed-in data_format doesn&#39;t have a channel dimension.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">_ConvND</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">custom_getter</span><span class="o">=</span><span class="n">custom_getter</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_format</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span> <span class="o">=</span> <span class="n">output_channels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span> <span class="o">=</span> <span class="n">_fill_and_verify_parameter_shape</span><span class="p">(</span><span class="n">kernel_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n</span><span class="p">,</span>
                                                          <span class="s2">&quot;kernel&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span> <span class="o">=</span> <span class="n">data_format</span>

    <span class="c1"># The following is for backwards-compatibility from when we used to accept</span>
    <span class="c1"># N-strides of the form [1, ..., 1].</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">collections</span><span class="o">.</span><span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_format</span><span class="p">)):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">stride</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_stride</span> <span class="o">=</span> <span class="n">_fill_and_verify_parameter_shape</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n</span><span class="p">,</span> <span class="s2">&quot;stride&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_rate</span> <span class="o">=</span> <span class="n">_fill_and_verify_parameter_shape</span><span class="p">(</span><span class="n">rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n</span><span class="p">,</span> <span class="s2">&quot;rate&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stride</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rate</span><span class="p">):</span>
      <span class="k">raise</span> <span class="n">base</span><span class="o">.</span><span class="n">NotSupportedError</span><span class="p">(</span><span class="s2">&quot;Cannot have stride &gt; 1 with rate &gt; 1&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_padding</span> <span class="o">=</span> <span class="n">_verify_padding</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_use_bias</span> <span class="o">=</span> <span class="n">use_bias</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">possible_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_possible_initializer_keys</span><span class="p">(</span><span class="n">use_bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">check_initializers</span><span class="p">(</span>
        <span class="n">initializers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">possible_keys</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">check_partitioners</span><span class="p">(</span>
        <span class="n">partitioners</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">possible_keys</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">check_regularizers</span><span class="p">(</span>
        <span class="n">regularizers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">possible_keys</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float16</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="ow">or</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">bfloat16</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="ow">or</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="ow">or</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="o">.</span><span class="n">dtype</span><span class="p">)):</span>
          <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
              <span class="s2">&quot;Mask needs to have dtype float16, bfloat16, float32 or float64&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">is_fully_defined</span><span class="p">():</span>
          <span class="n">base</span><span class="o">.</span><span class="n">IncompatibleShapeError</span><span class="p">(</span>
              <span class="s2">&quot;Mask needs to have a statically defined shape&quot;</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Invalid type for mask: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">mask</span><span class="p">)))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_channel_index</span> <span class="o">=</span> <span class="n">_find_channel_index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">)</span>

  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">get_possible_initializer_keys</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">}</span> <span class="k">if</span> <span class="n">use_bias</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;w&quot;</span><span class="p">}</span>

  <span class="k">def</span> <span class="nf">_build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Connects the _ConvND module into the graph, with input Tensor `inputs`.</span>

<span class="sd">    If this is not the first time the module has been connected to the graph,</span>
<span class="sd">    the input Tensor provided here must have the same final N-1 dimensions, in</span>
<span class="sd">    order for the existing variables to be the correct size for the</span>
<span class="sd">    multiplication; the batch size may differ for each connection.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: A ND Tensor of the same rank as `data_format`, and either of types</span>
<span class="sd">      `tf.float16`, `tf.bfloat16` or `tf.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A ND Tensor of shape [batch_size, output_dim_1, output_dim_2, ...,</span>
<span class="sd">          output_channels].</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If connecting the module into the graph any time after the</span>
<span class="sd">          first time and the inferred size of the input does not match previous</span>
<span class="sd">          invocations.</span>
<span class="sd">      base.IncompatibleShapeError: If the input tensor has the wrong number</span>
<span class="sd">          of dimensions.</span>
<span class="sd">      base.UnderspecifiedError: If the channel dimension of `inputs` isn&#39;t</span>
<span class="sd">          defined.</span>
<span class="sd">      base.IncompatibleShapeError: If a mask is present and its shape is</span>
<span class="sd">          incompatible with the shape of the weights.</span>
<span class="sd">      TypeError: If input Tensor dtype is not compatible with either</span>
<span class="sd">          `tf.float16`, `tf.bfloat16` or `tf.float32`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_verify_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_channel_index</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_channel_index</span><span class="p">]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_construct_w</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_mask</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_w</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_conv</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_bias</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_b</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">_apply_bias</span><span class="p">(</span>
          <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_channel_index</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">,</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span><span class="p">,</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">outputs</span>

  <span class="k">def</span> <span class="nf">_apply_conv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply a convolution operation on `inputs` using variable `w`.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: A Tensor of shape `data_format` and of type `tf.float16`,</span>
<span class="sd">          `tf.bfloat16` or `tf.float32`.</span>
<span class="sd">      w: A weight matrix of the same type as `inputs`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      outputs: The result of the convolution operation on `inputs`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stride</span><span class="p">,</span>
                                <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_padding</span><span class="p">,</span> <span class="n">dilation_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_rate</span><span class="p">,</span>
                                <span class="n">data_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span>

  <span class="k">def</span> <span class="nf">_construct_w</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Construct the convolution weight matrix.</span>

<span class="sd">    Figures out the shape of the weight matrix, initialize it, and return it.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: A Tensor of shape `data_format` and of type `tf.float16`,</span>
<span class="sd">          `tf.bfloat16` or `tf.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      w: A weight matrix of the same type as `inputs`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">weight_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span><span class="p">,</span>
                                         <span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span><span class="p">)</span>

    <span class="k">if</span> <span class="s2">&quot;w&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">[</span><span class="s2">&quot;w&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">create_weight_initializer</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                                          <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">,</span>
                        <span class="n">shape</span><span class="o">=</span><span class="n">weight_shape</span><span class="p">,</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                        <span class="n">initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">[</span><span class="s2">&quot;w&quot;</span><span class="p">],</span>
                        <span class="n">partitioner</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                        <span class="n">regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">w</span>

  <span class="k">def</span> <span class="nf">_apply_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Applies the passed-in mask to the convolution matrix.</span>

<span class="sd">    Returns:</span>
<span class="sd">      w: A copy of the convolution matrix that has had the mask applied.</span>

<span class="sd">    Raises:</span>
<span class="sd">      base.IncompatibleShapeError: If the mask shape has more dimensions than</span>
<span class="sd">          the weight matrix.</span>
<span class="sd">      base.IncompatibleShapeError: If the mask and the weight matrix don&#39;t</span>
<span class="sd">          match on shape.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_w</span>
    <span class="n">w_shape</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
    <span class="n">mask_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">mask_shape</span><span class="o">.</span><span class="n">ndims</span> <span class="o">&gt;</span> <span class="n">w_shape</span><span class="o">.</span><span class="n">ndims</span><span class="p">:</span>
      <span class="k">raise</span> <span class="n">base</span><span class="o">.</span><span class="n">IncompatibleShapeError</span><span class="p">(</span>
          <span class="s2">&quot;Invalid mask shape: </span><span class="si">{}</span><span class="s2">. Max shape: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
              <span class="n">mask_shape</span><span class="o">.</span><span class="n">ndims</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">)</span>
          <span class="p">)</span>
      <span class="p">)</span>
    <span class="k">if</span> <span class="n">mask_shape</span> <span class="o">!=</span> <span class="n">w_shape</span><span class="p">[:</span><span class="n">mask_shape</span><span class="o">.</span><span class="n">ndims</span><span class="p">]:</span>
      <span class="k">raise</span> <span class="n">base</span><span class="o">.</span><span class="n">IncompatibleShapeError</span><span class="p">(</span>
          <span class="s2">&quot;Invalid mask shape: </span><span class="si">{}</span><span class="s2">. Weight shape: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
              <span class="n">mask_shape</span><span class="p">,</span> <span class="n">w_shape</span>
          <span class="p">)</span>
      <span class="p">)</span>
    <span class="c1"># TF broadcasting is a bit fragile.</span>
    <span class="c1"># Expand the shape of self._mask by one dim at a time to the right</span>
    <span class="c1"># until the rank matches `weight_shape`.</span>
    <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span> <span class="o">&lt;</span> <span class="n">w_shape</span><span class="o">.</span><span class="n">ndims</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># tf.Variable &amp; tf.ResourceVariable don&#39;t support *=.</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span>  <span class="c1"># pylint: disable=g-no-augmented-assignment</span>

    <span class="k">return</span> <span class="n">w</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">output_channels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the number of output channels.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span><span class="p">()</span>
    <span class="c1"># Channel must be integer.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">kernel_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the kernel shape.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">stride</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the stride.&quot;&quot;&quot;</span>
    <span class="c1"># Backwards compatibility with old stride format.</span>

    <span class="k">return</span> <span class="n">_fill_and_one_pad_stride</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stride</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">)</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">rate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the dilation rate.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rate</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">padding</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the padding algorithm.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_padding</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">w</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the Variable containing the weight matrix.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_is_connected</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_w</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">b</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the Variable containing the bias.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Variable object containing the bias, from the most recent __call__.</span>

<span class="sd">    Raises:</span>
<span class="sd">      base.NotConnectedError: If the module has not been connected to the graph</span>
<span class="sd">          yet, meaning the variables do not exist.</span>
<span class="sd">      AttributeError: If the module does not use bias.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_is_connected</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_bias</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
          <span class="s2">&quot;No bias Variable in Conv2D Module when `use_bias=False`.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_b</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">has_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns `True` if bias Variable is present in the module.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_bias</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">initializers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the initializers dictionary.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">partitioners</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the partitioners dictionary.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">regularizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the regularizers dictionary.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">mask</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the mask.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">data_format</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the data format.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span>

  <span class="c1"># Implements Transposable interface.</span>
  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">input_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the input shape.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_is_connected</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">input_channels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the number of input channels.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_is_connected</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span>

  <span class="k">def</span> <span class="nf">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a cloned `_ConvND` module.</span>

<span class="sd">    Args:</span>
<span class="sd">      name: Optional string assigning name of cloned module. The default name</span>
<span class="sd">        is constructed by appending &quot;_clone&quot; to `self.module_name`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A copy of the current class.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_name</span> <span class="o">+</span> <span class="s2">&quot;_clone&quot;</span>

    <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)(</span><span class="n">output_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span><span class="p">,</span>
                      <span class="n">kernel_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span><span class="p">,</span>
                      <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stride</span><span class="p">,</span>
                      <span class="n">rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_rate</span><span class="p">,</span>
                      <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_padding</span><span class="p">,</span>
                      <span class="n">use_bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_bias</span><span class="p">,</span>
                      <span class="n">initializers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">,</span>
                      <span class="n">partitioners</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span><span class="p">,</span>
                      <span class="n">regularizers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span><span class="p">,</span>
                      <span class="n">mask</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="p">,</span>
                      <span class="n">data_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">,</span>
                      <span class="n">custom_getter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_custom_getter</span><span class="p">,</span>
                      <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_ConvNDTranspose</span><span class="p">(</span><span class="n">base</span><span class="o">.</span><span class="n">AbstractModule</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Spatial transposed / reverse / up ND convolution module, including bias.</span>

<span class="sd">  This acts as a light wrapper around the TensorFlow `conv_nd_transpose` ops,</span>
<span class="sd">  abstracting away variable creation and sharing.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">SAME</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">initializers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">partitioners</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regularizers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">data_format</span><span class="o">=</span><span class="n">DATA_FORMAT_NHWC</span><span class="p">,</span> <span class="n">custom_getter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv_nd_transpose&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a `ConvNDTranspose module`. Support for N = (1, 2, 3).</span>

<span class="sd">    See the following documentation for an explanation of VALID versus SAME</span>
<span class="sd">    padding modes:</span>
<span class="sd">    https://www.tensorflow.org/api_guides/python/nn#Convolution</span>

<span class="sd">    Args:</span>
<span class="sd">      output_channels: Number of output channels.</span>
<span class="sd">          Can be either a number or a callable. In the latter case, since the</span>
<span class="sd">          function invocation is deferred to graph construction time, the user</span>
<span class="sd">          must only ensure `output_channels` can be called, returning an</span>
<span class="sd">          integer, when build is called.</span>
<span class="sd">      output_shape: Output shape of transpose convolution.</span>
<span class="sd">          Can be either an iterable of integers or `Dimension`s, a</span>
<span class="sd">          `TensorShape`, or a callable. In the latter case, since the function</span>
<span class="sd">          invocation is deferred to graph construction time, the user must only</span>
<span class="sd">          ensure that `output_shape` can be called, returning an iterable of</span>
<span class="sd">          output shapes when `build` is called. Note that `output_shape` defines</span>
<span class="sd">          the size of output signal domain, as opposed to the shape of the</span>
<span class="sd">          output `Tensor`. If a None value is given, a default shape is</span>
<span class="sd">          automatically calculated (see docstring of</span>
<span class="sd">          `_default_transpose_size` function for more details).</span>
<span class="sd">      kernel_shape: Sequence of kernel sizes (of size N), or integer that is</span>
<span class="sd">          used to define kernel size in all dimensions.</span>
<span class="sd">      stride: Sequence of kernel strides (of size N), or integer that is used</span>
<span class="sd">          to define stride in all dimensions.</span>
<span class="sd">      padding: Padding algorithm, either `snt.SAME` or `snt.VALID`.</span>
<span class="sd">      use_bias: Whether to include bias parameters. Default `True`.</span>
<span class="sd">      initializers: Optional dict containing ops to initialize the filters (with</span>
<span class="sd">          key &#39;w&#39;) or biases (with key &#39;b&#39;).</span>
<span class="sd">      partitioners: Optional dict containing partitioners to partition</span>
<span class="sd">          weights (with key &#39;w&#39;) or biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          partitioners are used.</span>
<span class="sd">      regularizers: Optional dict containing regularizers for the filters</span>
<span class="sd">          (with key &#39;w&#39;) and the biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          regularizers are used. A regularizer should be a function that takes</span>
<span class="sd">          a single `Tensor` as an input and returns a scalar `Tensor` output,</span>
<span class="sd">          e.g. the L1 and L2 regularizers in `tf.contrib.layers`.</span>
<span class="sd">      data_format: The data format of the input.</span>
<span class="sd">      custom_getter: Callable or dictionary of callables to use as</span>
<span class="sd">          custom getters inside the module. If a dictionary, the keys</span>
<span class="sd">          correspond to regexes to match variable names. See the</span>
<span class="sd">          `tf.get_variable` documentation for information about the</span>
<span class="sd">          custom_getter API.</span>
<span class="sd">      name: Name of the module.</span>

<span class="sd">    Raises:</span>
<span class="sd">      base.IncompatibleShapeError: If the given kernel shape is neither an</span>
<span class="sd">          integer nor a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given stride is neither an integer nor</span>
<span class="sd">          a sequence of two or four integers.</span>
<span class="sd">      ValueError: If the given padding is not `snt.VALID` or `snt.SAME`.</span>
<span class="sd">      ValueError: If the given kernel_shape is `None`.</span>
<span class="sd">      KeyError: If `initializers`, `partitioners` or `regularizers` contain any</span>
<span class="sd">          keys other than &#39;w&#39; or &#39;b&#39;.</span>
<span class="sd">      TypeError: If any of the given initializers, partitioners or regularizers</span>
<span class="sd">          are not callable.</span>
<span class="sd">      ValueError: If the passed-in data_format doesn&#39;t have a channel dimension.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">_ConvNDTranspose</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">custom_getter</span><span class="o">=</span><span class="n">custom_getter</span><span class="p">,</span>
                                           <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span> <span class="o">=</span> <span class="n">data_format</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
      <span class="k">raise</span> <span class="n">base</span><span class="o">.</span><span class="n">NotSupportedError</span><span class="p">(</span>
          <span class="s2">&quot;We only support (1, 2, 3) convolution transpose operations. &quot;</span>
          <span class="s2">&quot;Received data format of: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span> <span class="o">=</span> <span class="n">output_channels</span>

    <span class="k">if</span> <span class="n">output_shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_use_default_output_shape</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_use_default_output_shape</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">output_shape</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span> <span class="o">=</span> <span class="n">output_shape</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span> <span class="o">=</span> <span class="n">_fill_and_verify_parameter_shape</span><span class="p">(</span><span class="n">output_shape</span><span class="p">,</span>
                                                              <span class="bp">self</span><span class="o">.</span><span class="n">_n</span><span class="p">,</span>
                                                              <span class="s2">&quot;output_shape&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">kernel_shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`kernel_shape` cannot be None.&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span> <span class="o">=</span> <span class="n">_fill_and_verify_parameter_shape</span><span class="p">(</span><span class="n">kernel_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n</span><span class="p">,</span>
                                                          <span class="s2">&quot;kernel&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">collections</span><span class="o">.</span><span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_format</span><span class="p">)):</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;C&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">stride</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
          <span class="k">raise</span> <span class="n">base</span><span class="o">.</span><span class="n">IncompatibleShapeError</span><span class="p">(</span>
              <span class="s2">&quot;Invalid stride: First and last element must be 1.&quot;</span><span class="p">)</span>
      <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;NC&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
          <span class="k">raise</span> <span class="n">base</span><span class="o">.</span><span class="n">IncompatibleShapeError</span><span class="p">(</span>
              <span class="s2">&quot;Invalid stride: First and second element must be 1.&quot;</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_stride</span> <span class="o">=</span> <span class="n">_fill_and_one_pad_stride</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n</span><span class="p">,</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_padding</span> <span class="o">=</span> <span class="n">_verify_padding</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_use_bias</span> <span class="o">=</span> <span class="n">use_bias</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">possible_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_possible_initializer_keys</span><span class="p">(</span><span class="n">use_bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">check_initializers</span><span class="p">(</span>
        <span class="n">initializers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">possible_keys</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">check_partitioners</span><span class="p">(</span>
        <span class="n">partitioners</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">possible_keys</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">check_regularizers</span><span class="p">(</span>
        <span class="n">regularizers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">possible_keys</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_channel_index</span> <span class="o">=</span> <span class="n">_find_channel_index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">)</span>

  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">get_possible_initializer_keys</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">}</span> <span class="k">if</span> <span class="n">use_bias</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;w&quot;</span><span class="p">}</span>

  <span class="k">def</span> <span class="nf">_build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Connects the _ConvNDTranspose module into the graph.</span>

<span class="sd">    If this is not the first time the module has been connected to the graph,</span>
<span class="sd">    the input Tensor provided here must have the same final N dimensions, in</span>
<span class="sd">    order for the existing variables to be the correct size for the</span>
<span class="sd">    multiplication. The batch size may differ for each connection.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: A Tensor of shape `data_format` and of type</span>
<span class="sd">          `tf.float16`, `tf.bfloat16` or `tf.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A Tensor of shape `data_format` and of type `tf.float16`, `tf.bfloat16`</span>
<span class="sd">          or `tf.float32`.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If connecting the module into the graph any time after the</span>
<span class="sd">          first time and the inferred size of the input does not match previous</span>
<span class="sd">          invocations.</span>
<span class="sd">      base.IncompatibleShapeError: If the input tensor has the wrong number</span>
<span class="sd">          of dimensions.</span>
<span class="sd">      base.UnderspecifiedError: If the channel dimension of `inputs` isn&#39;t</span>
<span class="sd">          defined.</span>
<span class="sd">      base.IncompatibleShapeError: If `output_shape` is an iterable and is not</span>
<span class="sd">          in the format `(out_height, out_width)`.</span>
<span class="sd">      TypeError: If input Tensor dtype is not compatible with either</span>
<span class="sd">          `tf.float16`, `tf.bfloat16` or `tf.float32`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_verify_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_channel_index</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_channel_index</span><span class="p">]</span>

    <span class="c1"># First, figure out what the non-(N,C) dims will be.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_default_output_shape</span><span class="p">:</span>
      <span class="k">def</span> <span class="nf">_default_transpose_size_wrapper</span><span class="p">():</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;NC&quot;</span><span class="p">):</span>
          <span class="n">input_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
          <span class="n">stride</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># self._data_format == N*WC</span>
          <span class="n">input_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
          <span class="n">stride</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">_default_transpose_size</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span>
                                       <span class="n">stride</span><span class="p">,</span>
                                       <span class="n">kernel_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span><span class="p">,</span>
                                       <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_padding</span><span class="p">)</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span> <span class="o">=</span> <span class="n">_default_transpose_size_wrapper</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n</span><span class="p">:</span>
      <span class="k">raise</span> <span class="n">base</span><span class="o">.</span><span class="n">IncompatibleShapeError</span><span class="p">(</span>
          <span class="s2">&quot;Output shape must have rank </span><span class="si">{}</span><span class="s2">, but instead was </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">_n</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span><span class="p">)))</span>

    <span class="c1"># Now, construct the size of the output, including the N + C dims.</span>
    <span class="n">output_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_infer_all_output_dims</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_construct_w</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="c1"># Add a dimension for the height.</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span> <span class="o">==</span> <span class="n">DATA_FORMAT_NWC</span><span class="p">:</span>
        <span class="n">h_dim</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">two_dim_conv_data_format</span> <span class="o">=</span> <span class="n">DATA_FORMAT_NHWC</span>
      <span class="k">else</span><span class="p">:</span>  <span class="c1"># self._data_format == DATA_FORMAT_NCW</span>
        <span class="n">h_dim</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">two_dim_conv_data_format</span> <span class="o">=</span> <span class="n">DATA_FORMAT_NCHW</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">h_dim</span><span class="p">)</span>
      <span class="n">two_dim_conv_stride</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">[:</span><span class="n">h_dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">[</span><span class="n">h_dim</span><span class="p">:]</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d_transpose</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">_w</span><span class="p">,</span>
                                       <span class="n">output_shape</span><span class="p">,</span>
                                       <span class="n">strides</span><span class="o">=</span><span class="n">two_dim_conv_stride</span><span class="p">,</span>
                                       <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_padding</span><span class="p">,</span>
                                       <span class="n">data_format</span><span class="o">=</span><span class="n">two_dim_conv_data_format</span><span class="p">)</span>
      <span class="c1"># Remove the height dimension to return a 3D tensor.</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="p">[</span><span class="n">h_dim</span><span class="p">])</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d_transpose</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">_w</span><span class="p">,</span>
                                       <span class="n">output_shape</span><span class="p">,</span>
                                       <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stride</span><span class="p">,</span>
                                       <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_padding</span><span class="p">,</span>
                                       <span class="n">data_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv3d_transpose</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">_w</span><span class="p">,</span>
                                       <span class="n">output_shape</span><span class="p">,</span>
                                       <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stride</span><span class="p">,</span>
                                       <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_padding</span><span class="p">,</span>
                                       <span class="n">data_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_bias</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_b</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">_apply_bias</span><span class="p">(</span>
          <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_channel_index</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">,</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span><span class="p">,</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span><span class="p">)</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recover_shape_information</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span>

  <span class="k">def</span> <span class="nf">_construct_w</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Construct the convolution weight matrix.</span>

<span class="sd">    Figures out the shape of the weight matrix, initialize it, and return it.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: A Tensor of shape `data_format` and of type `tf.float16`,</span>
<span class="sd">          `tf.bfloat16` or `tf.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      w: A weight matrix of the same type as `inputs`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Height dim needs to be added to everything for 1D Conv</span>
    <span class="c1"># as we&#39;ll be using the 2D Conv Transpose op.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">weight_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span><span class="p">,</span>
                                                  <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">weight_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span><span class="p">,</span>
                                           <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span><span class="p">)</span>

    <span class="k">if</span> <span class="s2">&quot;w&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">:</span>
      <span class="n">fan_in_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span><span class="p">,)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">[</span><span class="s2">&quot;w&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">create_weight_initializer</span><span class="p">(</span><span class="n">fan_in_shape</span><span class="p">,</span>
                                                          <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">,</span>
                        <span class="n">shape</span><span class="o">=</span><span class="n">weight_shape</span><span class="p">,</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                        <span class="n">initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">[</span><span class="s2">&quot;w&quot;</span><span class="p">],</span>
                        <span class="n">partitioner</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                        <span class="n">regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">w</span>

  <span class="k">def</span> <span class="nf">_infer_all_output_dims</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculate the output shape for `inputs` after a deconvolution.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: A Tensor of shape `data_format` and of type `tf.float16`,</span>
<span class="sd">          `tf.bfloat16` or `tf.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      output_shape: A tensor of shape (`batch_size`, `conv_output_shape`).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Use tensorflow shape op to manipulate inputs shape, so that unknown batch</span>
    <span class="c1"># size - which can happen when using input placeholders - is handled</span>
    <span class="c1"># correcly.</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">out_channels</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span><span class="p">,)</span>

    <span class="c1"># Height dim needs to be added to everything for 1D Conv</span>
    <span class="c1"># as we&#39;ll be using the 2D Conv Transpose op.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">out_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">out_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;NC&quot;</span><span class="p">):</span>
      <span class="n">out_shape_tuple</span> <span class="o">=</span> <span class="n">out_channels</span> <span class="o">+</span> <span class="n">out_shape</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;C&quot;</span><span class="p">):</span>
      <span class="n">out_shape_tuple</span> <span class="o">=</span> <span class="n">out_shape</span> <span class="o">+</span> <span class="n">out_channels</span>

    <span class="n">output_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">out_shape_tuple</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output_shape</span>

  <span class="k">def</span> <span class="nf">_recover_shape_information</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Recover output tensor shape value to enable shape inference.</span>

<span class="sd">    The batch size of `inputs` isn&#39;t preserved by the convolution op. Calculate</span>
<span class="sd">    what the proper output shape will be for `outputs`.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: A Tensor of shape `data_format` and of type `tf.float16`,</span>
<span class="sd">          `tf.bfloat16` or `tf.float32`.</span>
<span class="sd">      outputs: A Tensor of shape `data_format` and of type `tf.float16`,</span>
<span class="sd">          `tf.bfloat16` or `tf.float32`. The output of `inputs` from a transpose</span>
<span class="sd">          convolution op.</span>

<span class="sd">    Returns:</span>
<span class="sd">      outputs: The passed-in `outputs` with all shape information filled in.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batch_size_value</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;NC&quot;</span><span class="p">):</span>
      <span class="n">output_shape_value</span> <span class="o">=</span> <span class="p">((</span><span class="n">batch_size_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span><span class="p">)</span> <span class="o">+</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;C&quot;</span><span class="p">):</span>
      <span class="n">output_shape_value</span> <span class="o">=</span> <span class="p">((</span><span class="n">batch_size_value</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span> <span class="o">+</span>
                            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span><span class="p">,))</span>
    <span class="n">outputs</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">output_shape_value</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">output_channels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the number of output channels.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span><span class="p">()</span>
    <span class="c1"># Channel must be integer.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">kernel_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the kernel shape.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">stride</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the stride.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stride</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the output shape.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_is_connected</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">())</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">padding</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the padding algorithm.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_padding</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">w</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the Variable containing the weight matrix.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_is_connected</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_w</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">b</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the Variable containing the bias.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Variable object containing the bias, from the most recent __call__.</span>

<span class="sd">    Raises:</span>
<span class="sd">      base.NotConnectedError: If the module has not been connected to the graph</span>
<span class="sd">          yet, meaning the variables do not exist.</span>
<span class="sd">      AttributeError: If the module does not use bias.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_is_connected</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_bias</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
          <span class="s2">&quot;No bias Variable in Conv2DTranspose Module when `use_bias=False`.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_b</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">has_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns `True` if bias Variable is present in the module.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_bias</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">initializers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the initializers dictionary.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">partitioners</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the partitioners dictionary.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">regularizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the regularizers dictionary.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">input_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the input shape.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_is_connected</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">input_channels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the number of input channels.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_is_connected</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span>


<div class="viewcode-block" id="Conv1D"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.Conv1D">[docs]</a><span class="k">class</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="n">_ConvND</span><span class="p">,</span> <span class="n">base</span><span class="o">.</span><span class="n">Transposable</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;1D convolution module, including optional bias.</span>

<span class="sd">  This acts as a light wrapper around the class `_ConvND`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">padding</span><span class="o">=</span><span class="n">SAME</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">initializers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">partitioners</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regularizers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">data_format</span><span class="o">=</span><span class="n">DATA_FORMAT_NWC</span><span class="p">,</span> <span class="n">custom_getter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv_1d&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a Conv1D module.</span>

<span class="sd">    See the following documentation for an explanation of VALID versus SAME</span>
<span class="sd">    padding modes:</span>
<span class="sd">    https://www.tensorflow.org/api_guides/python/nn#Convolution</span>

<span class="sd">    Args:</span>
<span class="sd">      output_channels: Number of output channels. `output_channels` can be</span>
<span class="sd">          either a number or a callable. In the latter case, since the function</span>
<span class="sd">          invocation is deferred to graph construction time, the user must only</span>
<span class="sd">          ensure that output_channels can be called, returning an integer,</span>
<span class="sd">          when `build` is called.</span>
<span class="sd">      kernel_shape: Sequence of kernel sizes (of size 1), or integer that is</span>
<span class="sd">          used to define kernel size in all dimensions.</span>
<span class="sd">      stride: Sequence of kernel strides (of size 1), or integer that is used to</span>
<span class="sd">          define stride in all dimensions.</span>
<span class="sd">      rate: Sequence of dilation rates (of size 1), or integer that is used to</span>
<span class="sd">          define dilation rate in all dimensions. 1 corresponds to standard</span>
<span class="sd">          convolution, `rate &gt; 1` corresponds to dilated convolution. Cannot be</span>
<span class="sd">          &gt; 1 if any of `stride` is also &gt; 1.</span>
<span class="sd">      padding: Padding algorithm, either `snt.SAME` or `snt.VALID`.</span>
<span class="sd">      use_bias: Whether to include bias parameters. Default `True`.</span>
<span class="sd">      initializers: Optional dict containing ops to initialize the filters (with</span>
<span class="sd">          key &#39;w&#39;) or biases (with key &#39;b&#39;). The default initializer for the</span>
<span class="sd">          weights is a truncated normal initializer, which is commonly used</span>
<span class="sd">          when the inputs are zero centered (see</span>
<span class="sd">          https://arxiv.org/pdf/1502.03167v3.pdf). The default initializer for</span>
<span class="sd">          the bias is a zero initializer.</span>
<span class="sd">      partitioners: Optional dict containing partitioners to partition</span>
<span class="sd">          weights (with key &#39;w&#39;) or biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          partitioners are used.</span>
<span class="sd">      regularizers: Optional dict containing regularizers for the filters</span>
<span class="sd">          (with key &#39;w&#39;) and the biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          regularizers are used. A regularizer should be a function that takes</span>
<span class="sd">          a single `Tensor` as an input and returns a scalar `Tensor` output,</span>
<span class="sd">          e.g. the L1 and L2 regularizers in `tf.contrib.layers`.</span>
<span class="sd">      mask: A convertible to a 3D tensor which is multiplied</span>
<span class="sd">          component-wise with the weights (Optional).</span>
<span class="sd">      data_format: A string. Specifies whether the channel dimension</span>
<span class="sd">          of the input and output is the last dimension (default, NWC), or the</span>
<span class="sd">          second dimension (NCW).</span>
<span class="sd">      custom_getter: Callable or dictionary of callables to use as</span>
<span class="sd">          custom getters inside the module. If a dictionary, the keys</span>
<span class="sd">          correspond to regexes to match variable names. See the</span>
<span class="sd">          `tf.get_variable` documentation for information about the</span>
<span class="sd">          custom_getter API.</span>
<span class="sd">      name: Name of the module.</span>

<span class="sd">    Raises:</span>
<span class="sd">      base.IncompatibleShapeError: If the given kernel shape is not an integer;</span>
<span class="sd">          or if the given kernel shape is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given stride is not an integer; or if</span>
<span class="sd">          the given stride is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given rate is not an integer; or if</span>
<span class="sd">          the given rate is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If a mask is a TensorFlow Tensor with</span>
<span class="sd">          a not fully defined shape.</span>
<span class="sd">      base.NotSupportedError: If rate in any dimension and the stride in any</span>
<span class="sd">          dimension are simultaneously &gt; 1.</span>
<span class="sd">      ValueError: If the given padding is not `snt.VALID` or `snt.SAME`.</span>
<span class="sd">      KeyError: If `initializers`, `partitioners` or `regularizers` contain any</span>
<span class="sd">          keys other than &#39;w&#39; or &#39;b&#39;.</span>
<span class="sd">      TypeError: If any of the given initializers, partitioners or regularizers</span>
<span class="sd">          are not callable.</span>
<span class="sd">      TypeError: If mask is given and it is not convertible to a Tensor.</span>
<span class="sd">      ValueError: If the passed-in data_format doesn&#39;t have a channel dimension.</span>
<span class="sd">      ValueError: If the given data_format is not a supported format (see</span>
<span class="sd">          `SUPPORTED_1D_DATA_FORMATS`).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">data_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">SUPPORTED_1D_DATA_FORMATS</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid data_format </span><span class="si">{:s}</span><span class="s2">. Allowed formats &quot;</span>
                       <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data_format</span><span class="p">,</span> <span class="n">SUPPORTED_1D_DATA_FORMATS</span><span class="p">))</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">output_channels</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="o">=</span><span class="n">kernel_shape</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="n">rate</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">,</span>
        <span class="n">initializers</span><span class="o">=</span><span class="n">initializers</span><span class="p">,</span> <span class="n">partitioners</span><span class="o">=</span><span class="n">partitioners</span><span class="p">,</span>
        <span class="n">regularizers</span><span class="o">=</span><span class="n">regularizers</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span>
        <span class="n">custom_getter</span><span class="o">=</span><span class="n">custom_getter</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

  <span class="c1"># Implement Transposable interface</span>
<div class="viewcode-block" id="Conv1D.transpose"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.Conv1D.transpose">[docs]</a>  <span class="k">def</span> <span class="nf">transpose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns matching `Conv1DTranspose` module.</span>

<span class="sd">    Args:</span>
<span class="sd">      name: Optional string assigning name of transpose module. The default name</span>
<span class="sd">          is constructed by appending &quot;_transpose&quot; to `self.name`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      `Conv1DTranspose` module.</span>

<span class="sd">    Raises:</span>
<span class="sd">     base.NotSupportedError: If `rate` in any dimension &gt; 1.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rate</span><span class="p">):</span>
      <span class="k">raise</span> <span class="n">base</span><span class="o">.</span><span class="n">NotSupportedError</span><span class="p">(</span>
          <span class="s2">&quot;Cannot transpose a dilated convolution module.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">output_shape</span><span class="p">():</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span> <span class="o">==</span> <span class="n">DATA_FORMAT_NCW</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],)</span>
      <span class="k">else</span><span class="p">:</span>  <span class="c1"># data_format = DATA_FORMAT_NWC</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)</span>

    <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_name</span> <span class="o">+</span> <span class="s2">&quot;_transpose&quot;</span>
    <span class="k">return</span> <span class="n">Conv1DTranspose</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span><span class="p">,</span>
                           <span class="n">output_shape</span><span class="o">=</span><span class="n">output_shape</span><span class="p">,</span>
                           <span class="n">kernel_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span><span class="p">,</span>
                           <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stride</span><span class="p">,</span>
                           <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_padding</span><span class="p">,</span>
                           <span class="n">use_bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_bias</span><span class="p">,</span>
                           <span class="n">initializers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">,</span>
                           <span class="n">partitioners</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span><span class="p">,</span>
                           <span class="n">regularizers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span><span class="p">,</span>
                           <span class="n">data_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">,</span>
                           <span class="n">custom_getter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_custom_getter</span><span class="p">,</span>
                           <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="Conv1DTranspose"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.Conv1DTranspose">[docs]</a><span class="k">class</span> <span class="nc">Conv1DTranspose</span><span class="p">(</span><span class="n">_ConvNDTranspose</span><span class="p">,</span> <span class="n">base</span><span class="o">.</span><span class="n">Transposable</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;1D transposed / reverse / up 1D convolution module, including bias.</span>

<span class="sd">  This performs a 1D transpose convolution by lightly wrapping the TensorFlow op</span>
<span class="sd">  `tf.nn.conv2d_transpose`, setting the size of the height dimension of the</span>
<span class="sd">  image to 1.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">SAME</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">initializers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">partitioners</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regularizers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">data_format</span><span class="o">=</span><span class="n">DATA_FORMAT_NWC</span><span class="p">,</span> <span class="n">custom_getter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv_1d_transpose&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a Conv1DTranspose module.</span>

<span class="sd">    See the following documentation for an explanation of VALID versus SAME</span>
<span class="sd">    padding modes:</span>
<span class="sd">    https://www.tensorflow.org/api_guides/python/nn#Convolution</span>

<span class="sd">    Args:</span>
<span class="sd">      output_channels: Number of output channels. Can be either a number or a</span>
<span class="sd">          callable. In the latter case, since the function invocation is</span>
<span class="sd">          deferred to graph construction time, the user must only ensure</span>
<span class="sd">          `output_channels` can be called, returning an integer, when build is</span>
<span class="sd">          called.</span>
<span class="sd">      output_shape: Output shape of transpose convolution. Can be either a</span>
<span class="sd">          number or a callable. In the latter case, since the function</span>
<span class="sd">          invocation is deferred to graph construction time, the user must only</span>
<span class="sd">          ensure that `output_shape` can be called, returning an iterable of</span>
<span class="sd">          format `(out_length)` when build is called. If a None</span>
<span class="sd">          value is given, a default shape is automatically calculated (see</span>
<span class="sd">          docstring of _default_transpose_size function for more details).</span>
<span class="sd">      kernel_shape: Sequence of kernel sizes (of size 1), or integer that is</span>
<span class="sd">          used to define kernel size in all dimensions.</span>
<span class="sd">      stride: Sequence of kernel strides (of size 1), or integer that is used to</span>
<span class="sd">          define stride in all dimensions.</span>
<span class="sd">      padding: Padding algorithm, either `snt.SAME` or `snt.VALID`.</span>
<span class="sd">      use_bias: Whether to include bias parameters. Default `True`.</span>
<span class="sd">      initializers: Optional dict containing ops to initialize the filters (with</span>
<span class="sd">          key &#39;w&#39;) or biases (with key &#39;b&#39;).</span>
<span class="sd">      partitioners: Optional dict containing partitioners to partition</span>
<span class="sd">          weights (with key &#39;w&#39;) or biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          partitioners are used.</span>
<span class="sd">      regularizers: Optional dict containing regularizers for the filters</span>
<span class="sd">          (with key &#39;w&#39;) and the biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          regularizers are used. A regularizer should be a function that takes</span>
<span class="sd">          a single `Tensor` as an input and returns a scalar `Tensor` output,</span>
<span class="sd">          e.g. the L1 and L2 regularizers in `tf.contrib.layers`.</span>
<span class="sd">      data_format: A string. Specifies whether the channel dimension</span>
<span class="sd">          of the input and output is the last dimension (default, NWC), or the</span>
<span class="sd">          second dimension (NCW).</span>
<span class="sd">      custom_getter: Callable or dictionary of callables to use as</span>
<span class="sd">          custom getters inside the module. If a dictionary, the keys</span>
<span class="sd">          correspond to regexes to match variable names. See the</span>
<span class="sd">          `tf.get_variable` documentation for information about the</span>
<span class="sd">          custom_getter API.</span>
<span class="sd">      name: Name of the module.</span>

<span class="sd">    Raises:</span>
<span class="sd">      base.IncompatibleShapeError: If the given kernel shape is not an integer;</span>
<span class="sd">          or if the given kernel shape is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given stride is not an integer; or if</span>
<span class="sd">          the given stride is not a sequence of two or four integers.</span>
<span class="sd">      ValueError: If the given padding is not `snt.VALID` or `snt.SAME`.</span>
<span class="sd">      ValueError: If the given kernel_shape is `None`.</span>
<span class="sd">      KeyError: If `initializers`, `partitioners` or `regularizers` contain any</span>
<span class="sd">          keys other than &#39;w&#39; or &#39;b&#39;.</span>
<span class="sd">      TypeError: If any of the given initializers, partitioners or regularizers</span>
<span class="sd">          are not callable.</span>
<span class="sd">      ValueError: If the passed-in data_format doesn&#39;t have a channel dimension.</span>
<span class="sd">      ValueError: If the given data_format is not a supported format (see</span>
<span class="sd">          `SUPPORTED_1D_DATA_FORMATS`).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">data_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">SUPPORTED_1D_DATA_FORMATS</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid data_format </span><span class="si">{:s}</span><span class="s2">. Allowed formats &quot;</span>
                       <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data_format</span><span class="p">,</span> <span class="n">SUPPORTED_1D_DATA_FORMATS</span><span class="p">))</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">Conv1DTranspose</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">output_channels</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="n">output_shape</span><span class="p">,</span>
        <span class="n">kernel_shape</span><span class="o">=</span><span class="n">kernel_shape</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
        <span class="n">use_bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">,</span> <span class="n">initializers</span><span class="o">=</span><span class="n">initializers</span><span class="p">,</span>
        <span class="n">partitioners</span><span class="o">=</span><span class="n">partitioners</span><span class="p">,</span> <span class="n">regularizers</span><span class="o">=</span><span class="n">regularizers</span><span class="p">,</span>
        <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span> <span class="n">custom_getter</span><span class="o">=</span><span class="n">custom_getter</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
    <span class="p">)</span>

  <span class="c1"># Implement Transposable interface.</span>
<div class="viewcode-block" id="Conv1DTranspose.transpose"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.Conv1DTranspose.transpose">[docs]</a>  <span class="k">def</span> <span class="nf">transpose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns matching `Conv1D` module.</span>

<span class="sd">    Args:</span>
<span class="sd">      name: Optional string assigning name of transpose module. The default name</span>
<span class="sd">        is constructed by appending &quot;_transpose&quot; to `self.name`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      `Conv1D` module.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_name</span> <span class="o">+</span> <span class="s2">&quot;_transpose&quot;</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span> <span class="o">==</span> <span class="n">DATA_FORMAT_NWC</span><span class="p">:</span>
      <span class="n">stride</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stride</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># self._data_format == DATA_FORMAT_NCW</span>
      <span class="n">stride</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stride</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>

    <span class="k">return</span> <span class="n">Conv1D</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_channels</span><span class="p">,</span>
                  <span class="n">kernel_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_shape</span><span class="p">,</span>
                  <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
                  <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span>
                  <span class="n">use_bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_bias</span><span class="p">,</span>
                  <span class="n">initializers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">initializers</span><span class="p">,</span>
                  <span class="n">partitioners</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">partitioners</span><span class="p">,</span>
                  <span class="n">regularizers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">regularizers</span><span class="p">,</span>
                  <span class="n">data_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">,</span>
                  <span class="n">custom_getter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_custom_getter</span><span class="p">,</span>
                  <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="CausalConv1D"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.CausalConv1D">[docs]</a><span class="k">class</span> <span class="nc">CausalConv1D</span><span class="p">(</span><span class="n">_ConvND</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;1D convolution module, including optional bias.</span>

<span class="sd">  This acts as a light wrapper around _ConvND ensuring that the outputs at index</span>
<span class="sd">  `i` only depend on indices smaller than `i` (also known as a causal</span>
<span class="sd">  convolution). For further details on the theoretical background, refer to:</span>

<span class="sd">  https://arxiv.org/abs/1610.10099</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">,</span>
               <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">initializers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">partitioners</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regularizers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">padding</span><span class="o">=</span><span class="n">VALID</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="n">DATA_FORMAT_NWC</span><span class="p">,</span>
               <span class="n">custom_getter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;causal_conv_1d&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a CausalConv1D module.</span>

<span class="sd">    Args:</span>
<span class="sd">      output_channels: Number of output channels. `output_channels` can be</span>
<span class="sd">          either a number or a callable. In the latter case, since the function</span>
<span class="sd">          invocation is deferred to graph construction time, the user must only</span>
<span class="sd">          ensure that output_channels can be called, returning an integer,</span>
<span class="sd">          when `build` is called.</span>
<span class="sd">      kernel_shape: Sequence of kernel sizes (of size 1), or integer that is</span>
<span class="sd">          used to define kernel size in all dimensions.</span>
<span class="sd">      stride: Sequence of kernel strides (of size 1), or integer that is used to</span>
<span class="sd">          define stride in all dimensions.</span>
<span class="sd">      rate: Sequence of dilation rates (of size 1), or integer that is used to</span>
<span class="sd">          define dilation rate in all dimensions. 1 corresponds to standard</span>
<span class="sd">          convolution, `rate &gt; 1` corresponds to dilated convolution. Cannot be</span>
<span class="sd">          &gt; 1 if any of `stride` is also &gt; 1.</span>
<span class="sd">      use_bias: Whether to include bias parameters. Default `True`.</span>
<span class="sd">      initializers: Optional dict containing ops to initialize the filters (with</span>
<span class="sd">          key &#39;w&#39;) or biases (with key &#39;b&#39;). The default initializer for the</span>
<span class="sd">          weights is a truncated normal initializer, which is commonly used</span>
<span class="sd">          when the inputs are zero centered (see</span>
<span class="sd">          https://arxiv.org/pdf/1502.03167v3.pdf). The default initializer for</span>
<span class="sd">          the bias is a zero initializer.</span>
<span class="sd">      partitioners: Optional dict containing partitioners to partition</span>
<span class="sd">          weights (with key &#39;w&#39;) or biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          partitioners are used.</span>
<span class="sd">      regularizers: Optional dict containing regularizers for the filters</span>
<span class="sd">          (with key &#39;w&#39;) and the biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          regularizers are used. A regularizer should be a function that takes</span>
<span class="sd">          a single `Tensor` as an input and returns a scalar `Tensor` output,</span>
<span class="sd">          e.g. the L1 and L2 regularizers in `tf.contrib.layers`.</span>
<span class="sd">      mask: A convertible to a 3D tensor which is multiplied</span>
<span class="sd">          component-wise with the weights (Optional).</span>
<span class="sd">      padding: Padding algorithm. Must be `snt.VALID`.</span>
<span class="sd">      data_format: A string. Specifies whether the channel dimension</span>
<span class="sd">          of the input and output is the last dimension (default, NWC), or the</span>
<span class="sd">          second dimension (NCW).</span>
<span class="sd">      custom_getter: Callable or dictionary of callables to use as</span>
<span class="sd">          custom getters inside the module. If a dictionary, the keys</span>
<span class="sd">          correspond to regexes to match variable names. See the</span>
<span class="sd">          `tf.get_variable` documentation for information about the</span>
<span class="sd">          custom_getter API.</span>
<span class="sd">      name: Name of the module.</span>

<span class="sd">    Raises:</span>
<span class="sd">      base.IncompatibleShapeError: If the given kernel shape is not an integer;</span>
<span class="sd">          or if the given kernel shape is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given stride is not an integer; or if</span>
<span class="sd">          the given stride is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given rate is not an integer; or if</span>
<span class="sd">          the given rate is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If a mask is a TensorFlow Tensor with</span>
<span class="sd">          a not fully defined shape.</span>
<span class="sd">      base.NotSupportedError: If rate in any dimension and the stride in any</span>
<span class="sd">          dimension are simultaneously &gt; 1.</span>
<span class="sd">      ValueError: If the given padding is not `snt.VALID`.</span>
<span class="sd">      KeyError: If `initializers`, `partitioners` or `regularizers` contain any</span>
<span class="sd">          keys other than &#39;w&#39; or &#39;b&#39;.</span>
<span class="sd">      TypeError: If any of the given initializers, partitioners or regularizers</span>
<span class="sd">          are not callable.</span>
<span class="sd">      TypeError: If mask is given and it is not convertible to a Tensor.</span>
<span class="sd">      ValueError: If the passed-in data_format doesn&#39;t have a channel dimension.</span>
<span class="sd">      ValueError: If the given data_format is not a supported format (see</span>
<span class="sd">          `SUPPORTED_1D_DATA_FORMATS`).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">data_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">SUPPORTED_1D_DATA_FORMATS</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid data_format </span><span class="si">{:s}</span><span class="s2">. Allowed formats &quot;</span>
                       <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data_format</span><span class="p">,</span> <span class="n">SUPPORTED_1D_DATA_FORMATS</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">padding</span> <span class="o">!=</span> <span class="n">VALID</span><span class="p">:</span>
      <span class="k">raise</span> <span class="n">base</span><span class="o">.</span><span class="n">NotSupportedError</span><span class="p">(</span>
          <span class="s2">&quot;Causal padding requires padding argument to be VALID.&quot;</span>
          <span class="s2">&quot;Got: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">padding</span><span class="p">))</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">CausalConv1D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">output_channels</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="o">=</span><span class="n">kernel_shape</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="n">rate</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">,</span>
        <span class="n">initializers</span><span class="o">=</span><span class="n">initializers</span><span class="p">,</span> <span class="n">partitioners</span><span class="o">=</span><span class="n">partitioners</span><span class="p">,</span>
        <span class="n">regularizers</span><span class="o">=</span><span class="n">regularizers</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
        <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span>
        <span class="n">custom_getter</span><span class="o">=</span><span class="n">custom_getter</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_construct_causal_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Turn the input causal using padding.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: A Tensor of shape `data_format` and of type `tf.float16`,</span>
<span class="sd">          `tf.bfloat16` or `tf.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      inputs: The `inputs` argument that has had causal padding added.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pad_amount</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rate</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span> <span class="o">==</span> <span class="n">DATA_FORMAT_NCW</span><span class="p">:</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">pad_amount</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># self._data_format == DATA_FORMAT_NWC</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">pad_amount</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
    <span class="k">return</span> <span class="n">inputs</span>

  <span class="k">def</span> <span class="nf">_apply_conv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply a convolution operation on `inputs` using variable `w`.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: A Tensor of shape `data_format` and of type `tf.float16`,</span>
<span class="sd">          `tf.bfloat16` or `tf.float32`.</span>
<span class="sd">      w: A weight matrix of the same type as `inputs`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      outputs: The result of the convolution operation on `inputs`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_construct_causal_input</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">CausalConv1D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">_apply_conv</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span></div>


<div class="viewcode-block" id="Conv2D"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.Conv2D">[docs]</a><span class="k">class</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="n">_ConvND</span><span class="p">,</span> <span class="n">base</span><span class="o">.</span><span class="n">Transposable</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Spatial convolution and dilated convolution module, including bias.</span>

<span class="sd">  This acts as a light wrapper around the class `_ConvND`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">padding</span><span class="o">=</span><span class="n">SAME</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">initializers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">partitioners</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regularizers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">data_format</span><span class="o">=</span><span class="n">DATA_FORMAT_NHWC</span><span class="p">,</span> <span class="n">custom_getter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv_2d&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a Conv2D module.</span>

<span class="sd">    See the following documentation for an explanation of VALID versus SAME</span>
<span class="sd">    padding modes:</span>
<span class="sd">    https://www.tensorflow.org/api_guides/python/nn#Convolution</span>

<span class="sd">    Args:</span>
<span class="sd">      output_channels: Number of output channels. `output_channels` can be</span>
<span class="sd">          either a number or a callable. In the latter case, since the function</span>
<span class="sd">          invocation is deferred to graph construction time, the user must only</span>
<span class="sd">          ensure that output_channels can be called, returning an integer,</span>
<span class="sd">          when `build` is called.</span>
<span class="sd">      kernel_shape: Sequence of kernel sizes (of size 2), or integer that is</span>
<span class="sd">          used to define kernel size in all dimensions.</span>
<span class="sd">      stride: Sequence of kernel strides (of size 2), or integer that is used to</span>
<span class="sd">          define stride in all dimensions.</span>
<span class="sd">      rate: Sequence of dilation rates (of size 2), or integer that is used to</span>
<span class="sd">          define dilation rate in all dimensions. 1 corresponds to standard 2D</span>
<span class="sd">          convolution, `rate &gt; 1` corresponds to dilated convolution. Cannot be</span>
<span class="sd">          &gt; 1 if any of `stride` is also &gt; 1.</span>
<span class="sd">      padding: Padding algorithm, either `snt.SAME` or `snt.VALID`.</span>
<span class="sd">      use_bias: Whether to include bias parameters. Default `True`.</span>
<span class="sd">      initializers: Optional dict containing ops to initialize the filters (with</span>
<span class="sd">          key &#39;w&#39;) or biases (with key &#39;b&#39;). The default initializer for the</span>
<span class="sd">          weights is a truncated normal initializer, which is commonly used</span>
<span class="sd">          when the inputs are zero centered (see</span>
<span class="sd">          https://arxiv.org/pdf/1502.03167v3.pdf). The default initializer for</span>
<span class="sd">          the bias is a zero initializer.</span>
<span class="sd">      partitioners: Optional dict containing partitioners to partition</span>
<span class="sd">          weights (with key &#39;w&#39;) or biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          partitioners are used.</span>
<span class="sd">      regularizers: Optional dict containing regularizers for the filters</span>
<span class="sd">          (with key &#39;w&#39;) and the biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          regularizers are used. A regularizer should be a function that takes</span>
<span class="sd">          a single `Tensor` as an input and returns a scalar `Tensor` output,</span>
<span class="sd">          e.g. the L1 and L2 regularizers in `tf.contrib.layers`.</span>
<span class="sd">      mask: A convertible to a 4D tensor which is multiplied</span>
<span class="sd">          component-wise with the weights (Optional).</span>
<span class="sd">      data_format: A string. Specifies whether the channel dimension</span>
<span class="sd">          of the input and output is the last dimension (default, NHWC), or the</span>
<span class="sd">          second dimension (NCHW).</span>
<span class="sd">      custom_getter: Callable or dictionary of callables to use as</span>
<span class="sd">          custom getters inside the module. If a dictionary, the keys</span>
<span class="sd">          correspond to regexes to match variable names. See the</span>
<span class="sd">          `tf.get_variable` documentation for information about the</span>
<span class="sd">          custom_getter API.</span>
<span class="sd">      name: Name of the module.</span>

<span class="sd">    Raises:</span>
<span class="sd">      base.IncompatibleShapeError: If the given kernel shape is not an integer;</span>
<span class="sd">          or if the given kernel shape is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given stride is not an integer; or if</span>
<span class="sd">          the given stride is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given rate is not an integer; or if</span>
<span class="sd">          the given rate is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If a mask is given and its rank is neither 2</span>
<span class="sd">          nor 4, or if it is a TensorFlow Tensor with a not fully defined shape.</span>
<span class="sd">      base.NotSupportedError: If rate in any dimension and the stride in any</span>
<span class="sd">          dimension are simultaneously &gt; 1.</span>
<span class="sd">      ValueError: If the given padding is not `snt.VALID` or `snt.SAME`.</span>
<span class="sd">      KeyError: If `initializers`, `partitioners` or `regularizers` contain any</span>
<span class="sd">          keys other than &#39;w&#39; or &#39;b&#39;.</span>
<span class="sd">      TypeError: If any of the given initializers, partitioners or regularizers</span>
<span class="sd">          are not callable.</span>
<span class="sd">      TypeError: If mask is given and it is not convertible to a Tensor.</span>
<span class="sd">      ValueError: If the passed-in data_format doesn&#39;t have a channel dimension.</span>
<span class="sd">      ValueError: If the given data_format is not a supported format (see</span>
<span class="sd">        `SUPPORTED_2D_DATA_FORMATS`).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">data_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">SUPPORTED_2D_DATA_FORMATS</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid data_format </span><span class="si">{:s}</span><span class="s2">. Allowed formats &quot;</span>
                       <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data_format</span><span class="p">,</span> <span class="n">SUPPORTED_2D_DATA_FORMATS</span><span class="p">))</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">output_channels</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="o">=</span><span class="n">kernel_shape</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="n">rate</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">,</span>
        <span class="n">initializers</span><span class="o">=</span><span class="n">initializers</span><span class="p">,</span> <span class="n">partitioners</span><span class="o">=</span><span class="n">partitioners</span><span class="p">,</span>
        <span class="n">regularizers</span><span class="o">=</span><span class="n">regularizers</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span>
        <span class="n">custom_getter</span><span class="o">=</span><span class="n">custom_getter</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

  <span class="c1"># Implements Transposable interface.</span>
<div class="viewcode-block" id="Conv2D.transpose"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.Conv2D.transpose">[docs]</a>  <span class="k">def</span> <span class="nf">transpose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns matching `Conv2DTranspose` module.</span>

<span class="sd">    Args:</span>
<span class="sd">      name: Optional string assigning name of transpose module. The default name</span>
<span class="sd">        is constructed by appending &quot;_transpose&quot; to `self.name`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      `Conv2DTranspose` module.</span>

<span class="sd">    Raises:</span>
<span class="sd">     base.NotSupportedError: If `rate` in any dimension &gt; 1.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rate</span><span class="p">):</span>
      <span class="k">raise</span> <span class="n">base</span><span class="o">.</span><span class="n">NotSupportedError</span><span class="p">(</span>
          <span class="s2">&quot;Cannot transpose a dilated convolution module.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_name</span> <span class="o">+</span> <span class="s2">&quot;_transpose&quot;</span>

    <span class="k">def</span> <span class="nf">output_shape</span><span class="p">():</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span> <span class="o">==</span> <span class="n">DATA_FORMAT_NCHW</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span>
      <span class="k">else</span><span class="p">:</span>  <span class="c1"># data_format == DATA_FORMAT_NHWC</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">Conv2DTranspose</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span><span class="p">,</span>
                           <span class="n">output_shape</span><span class="o">=</span><span class="n">output_shape</span><span class="p">,</span>
                           <span class="n">kernel_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span><span class="p">,</span>
                           <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stride</span><span class="p">,</span>
                           <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_padding</span><span class="p">,</span>
                           <span class="n">use_bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_bias</span><span class="p">,</span>
                           <span class="n">initializers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">,</span>
                           <span class="n">partitioners</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span><span class="p">,</span>
                           <span class="n">regularizers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span><span class="p">,</span>
                           <span class="n">data_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">,</span>
                           <span class="n">custom_getter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_custom_getter</span><span class="p">,</span>
                           <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="Conv2DTranspose"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.Conv2DTranspose">[docs]</a><span class="k">class</span> <span class="nc">Conv2DTranspose</span><span class="p">(</span><span class="n">_ConvNDTranspose</span><span class="p">,</span> <span class="n">base</span><span class="o">.</span><span class="n">Transposable</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Spatial transposed / reverse / up 2D convolution module, including bias.</span>

<span class="sd">  This acts as a light wrapper around the TensorFlow op `tf.nn.conv2d_transpose`</span>
<span class="sd">  abstracting away variable creation and sharing.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">SAME</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">initializers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">partitioners</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regularizers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">data_format</span><span class="o">=</span><span class="n">DATA_FORMAT_NHWC</span><span class="p">,</span> <span class="n">custom_getter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv_2d_transpose&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a `Conv2DTranspose module`.</span>

<span class="sd">    See the following documentation for an explanation of VALID versus SAME</span>
<span class="sd">    padding modes:</span>
<span class="sd">    https://www.tensorflow.org/api_guides/python/nn#Convolution</span>

<span class="sd">    Args:</span>
<span class="sd">      output_channels: Number of output channels.</span>
<span class="sd">          Can be either a number or a callable. In the latter case, since the</span>
<span class="sd">          function invocation is deferred to graph construction time, the user</span>
<span class="sd">          must only ensure `output_channels` can be called, returning an</span>
<span class="sd">          integer, when build is called.</span>
<span class="sd">      output_shape: Output shape of transpose convolution.</span>
<span class="sd">          Can be either an iterable of integers or a callable. In the latter</span>
<span class="sd">          case, since the function invocation is deferred to graph construction</span>
<span class="sd">          time, the user must only ensure that `output_shape` can be called,</span>
<span class="sd">          returning an iterable of format `(out_height, out_width)` when `build`</span>
<span class="sd">          is called. Note that `output_shape` defines the size of output signal</span>
<span class="sd">          domain, as opposed to the shape of the output `Tensor`. If a None</span>
<span class="sd">          value is given, a default shape is automatically calculated (see</span>
<span class="sd">          docstring of _default_transpose_size function for more details).</span>
<span class="sd">      kernel_shape: Sequence of kernel sizes (of size 2), or integer that is</span>
<span class="sd">          used to define kernel size in all dimensions.</span>
<span class="sd">      stride: Sequence of kernel strides (of size 2), or integer that is used to</span>
<span class="sd">          define stride in all dimensions.</span>
<span class="sd">      padding: Padding algorithm, either `snt.SAME` or `snt.VALID`.</span>
<span class="sd">      use_bias: Whether to include bias parameters. Default `True`.</span>
<span class="sd">      initializers: Optional dict containing ops to initialize the filters (with</span>
<span class="sd">          key &#39;w&#39;) or biases (with key &#39;b&#39;).</span>
<span class="sd">      partitioners: Optional dict containing partitioners to partition</span>
<span class="sd">          weights (with key &#39;w&#39;) or biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          partitioners are used.</span>
<span class="sd">      regularizers: Optional dict containing regularizers for the filters</span>
<span class="sd">          (with key &#39;w&#39;) and the biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          regularizers are used. A regularizer should be a function that takes</span>
<span class="sd">          a single `Tensor` as an input and returns a scalar `Tensor` output,</span>
<span class="sd">          e.g. the L1 and L2 regularizers in `tf.contrib.layers`.</span>
<span class="sd">      data_format: A string. Specifies whether the channel dimension</span>
<span class="sd">          of the input and output is the last dimension (default, NHWC), or the</span>
<span class="sd">          second dimension (&quot;NCHW&quot;).</span>
<span class="sd">      custom_getter: Callable or dictionary of callables to use as</span>
<span class="sd">          custom getters inside the module. If a dictionary, the keys</span>
<span class="sd">          correspond to regexes to match variable names. See the`</span>
<span class="sd">          tf.get_variable` documentation for information about the</span>
<span class="sd">          custom_getter API.</span>
<span class="sd">      name: Name of the module.</span>

<span class="sd">    Raises:</span>
<span class="sd">      base.IncompatibleShapeError: If the given kernel shape is neither an</span>
<span class="sd">          integer nor a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given stride is neither an integer nor</span>
<span class="sd">          a sequence of two or four integers.</span>
<span class="sd">      ValueError: If the given padding is not `snt.VALID` or `snt.SAME`.</span>
<span class="sd">      ValueError: If the given kernel_shape is `None`.</span>
<span class="sd">      KeyError: If `initializers`, `partitioners` or `regularizers` contain any</span>
<span class="sd">          keys other than &#39;w&#39; or &#39;b&#39;.</span>
<span class="sd">      TypeError: If any of the given initializers, partitioners or regularizers</span>
<span class="sd">          are not callable.</span>
<span class="sd">      ValueError: If the passed-in data_format doesn&#39;t have a channel dimension.</span>
<span class="sd">      ValueError: If the given data_format is not a supported format (see</span>
<span class="sd">          `SUPPORTED_2D_DATA_FORMATS`).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">data_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">SUPPORTED_2D_DATA_FORMATS</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid data_format </span><span class="si">{:s}</span><span class="s2">. Allowed formats &quot;</span>
                       <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data_format</span><span class="p">,</span> <span class="n">SUPPORTED_2D_DATA_FORMATS</span><span class="p">))</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">Conv2DTranspose</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">output_channels</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="n">output_shape</span><span class="p">,</span>
        <span class="n">kernel_shape</span><span class="o">=</span><span class="n">kernel_shape</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
        <span class="n">use_bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">,</span> <span class="n">initializers</span><span class="o">=</span><span class="n">initializers</span><span class="p">,</span>
        <span class="n">partitioners</span><span class="o">=</span><span class="n">partitioners</span><span class="p">,</span> <span class="n">regularizers</span><span class="o">=</span><span class="n">regularizers</span><span class="p">,</span>
        <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span> <span class="n">custom_getter</span><span class="o">=</span><span class="n">custom_getter</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
    <span class="p">)</span>

  <span class="c1"># Implements Transposable interface.</span>
<div class="viewcode-block" id="Conv2DTranspose.transpose"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.Conv2DTranspose.transpose">[docs]</a>  <span class="k">def</span> <span class="nf">transpose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns matching `Conv2D` module.</span>

<span class="sd">    Args:</span>
<span class="sd">      name: Optional string assigning name of transpose module. The default name</span>
<span class="sd">          is constructed by appending &quot;_transpose&quot; to `self.name`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      `Conv2D` module.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_name</span> <span class="o">+</span> <span class="s2">&quot;_transpose&quot;</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span> <span class="o">==</span> <span class="n">DATA_FORMAT_NHWC</span><span class="p">:</span>
      <span class="n">stride</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stride</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># self._data_format == DATA_FORMAT_NCHW</span>
      <span class="n">stride</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stride</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>

    <span class="k">return</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_channels</span><span class="p">,</span>
                  <span class="n">kernel_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span><span class="p">,</span>
                  <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
                  <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_padding</span><span class="p">,</span>
                  <span class="n">use_bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_bias</span><span class="p">,</span>
                  <span class="n">initializers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">,</span>
                  <span class="n">partitioners</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span><span class="p">,</span>
                  <span class="n">regularizers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span><span class="p">,</span>
                  <span class="n">data_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">,</span>
                  <span class="n">custom_getter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_custom_getter</span><span class="p">,</span>
                  <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="Conv3D"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.Conv3D">[docs]</a><span class="k">class</span> <span class="nc">Conv3D</span><span class="p">(</span><span class="n">_ConvND</span><span class="p">,</span> <span class="n">base</span><span class="o">.</span><span class="n">Transposable</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Volumetric convolution module, including optional bias.</span>

<span class="sd">  This acts as a light wrapper around the class `_ConvND`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">padding</span><span class="o">=</span><span class="n">SAME</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">initializers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">partitioners</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regularizers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">data_format</span><span class="o">=</span><span class="n">DATA_FORMAT_NDHWC</span><span class="p">,</span> <span class="n">custom_getter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv_3d&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a Conv3D module.</span>

<span class="sd">    See the following documentation for an explanation of VALID versus SAME</span>
<span class="sd">    padding modes:</span>
<span class="sd">    https://www.tensorflow.org/api_guides/python/nn#Convolution</span>

<span class="sd">    Args:</span>
<span class="sd">      output_channels: Number of output channels. `output_channels` can be</span>
<span class="sd">          either a number or a callable. In the latter case, since the function</span>
<span class="sd">          invocation is deferred to graph construction time, the user must only</span>
<span class="sd">          ensure that output_channels can be called, returning an integer,</span>
<span class="sd">          when `build` is called.</span>
<span class="sd">      kernel_shape: Sequence of kernel sizes (of size 3), or integer that is</span>
<span class="sd">          used to define kernel size in all dimensions.</span>
<span class="sd">      stride: Sequence of kernel strides (of size 3), or integer that is used to</span>
<span class="sd">          define stride in all dimensions.</span>
<span class="sd">      rate: Sequence of dilation rates (of size 3), or integer that is used to</span>
<span class="sd">          define dilation rate in all dimensions. 1 corresponds to standard 2D</span>
<span class="sd">          convolution, `rate &gt; 1` corresponds to dilated convolution. Cannot be</span>
<span class="sd">          &gt; 1 if any of `stride` is also &gt; 1.</span>
<span class="sd">      padding: Padding algorithm, either `snt.SAME` or `snt.VALID`.</span>
<span class="sd">      use_bias: Whether to include bias parameters. Default `True`.</span>
<span class="sd">      initializers: Optional dict containing ops to initialize the filters (with</span>
<span class="sd">          key &#39;w&#39;) or biases (with key &#39;b&#39;). The default initializer for the</span>
<span class="sd">          weights is a truncated normal initializer, which is commonly used</span>
<span class="sd">          when the inputs are zero centered (see</span>
<span class="sd">          https://arxiv.org/pdf/1502.03167v3.pdf). The default initializer for</span>
<span class="sd">          the bias is a zero initializer.</span>
<span class="sd">      partitioners: Optional dict containing partitioners to partition</span>
<span class="sd">          weights (with key &#39;w&#39;) or biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          partitioners are used.</span>
<span class="sd">      regularizers: Optional dict containing regularizers for the filters</span>
<span class="sd">          (with key &#39;w&#39;) and the biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          regularizers are used. A regularizer should be a function that takes</span>
<span class="sd">          a single `Tensor` as an input and returns a scalar `Tensor` output,</span>
<span class="sd">          e.g. the L1 and L2 regularizers in `tf.contrib.layers`.</span>
<span class="sd">      mask: An object convertible to a 5D tensor which is multiplied</span>
<span class="sd">          component-wise with the weights (Optional).</span>
<span class="sd">      data_format: A string. Specifies whether the channel dimension</span>
<span class="sd">          of the input and output is the last dimension (default, NDHWC), or</span>
<span class="sd">          the second dimension (NCDHW).</span>
<span class="sd">      custom_getter: Callable or dictionary of callables to use as</span>
<span class="sd">          custom getters inside the module. If a dictionary, the keys</span>
<span class="sd">          correspond to regexes to match variable names. See the</span>
<span class="sd">          `tf.get_variable` documentation for information about the</span>
<span class="sd">          custom_getter API.</span>
<span class="sd">      name: Name of the module.</span>

<span class="sd">    Raises:</span>
<span class="sd">      base.IncompatibleShapeError: If the given kernel shape is not an integer;</span>
<span class="sd">          or if the given kernel shape is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given stride is not an integer; or if</span>
<span class="sd">          the given stride is not a sequence of two or four integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given rate is not an integer; or if</span>
<span class="sd">          the given rate is not a sequence of two integers.</span>
<span class="sd">      base.NotSupportedError: If rate in any dimension and the stride in any</span>
<span class="sd">          dimension are simultaneously &gt; 1.</span>
<span class="sd">      ValueError: If the given padding is not `snt.VALID` or `snt.SAME`.</span>
<span class="sd">      KeyError: If `initializers`, `partitioners` or `regularizers` contain any</span>
<span class="sd">          keys other than &#39;w&#39; or &#39;b&#39;.</span>
<span class="sd">      TypeError: If any of the given initializers, partitioners or regularizers</span>
<span class="sd">          are not callable.</span>
<span class="sd">      ValueError: If the passed-in data_format doesn&#39;t have a channel dimension.</span>
<span class="sd">      ValueError: If the given data_format is not a supported format (see</span>
<span class="sd">          `SUPPORTED_3D_DATA_FORMATS`).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">data_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">SUPPORTED_3D_DATA_FORMATS</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid data_format </span><span class="si">{:s}</span><span class="s2">. Allowed formats &quot;</span>
                       <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data_format</span><span class="p">,</span> <span class="n">SUPPORTED_3D_DATA_FORMATS</span><span class="p">))</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Conv3D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">output_channels</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="o">=</span><span class="n">kernel_shape</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="n">rate</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">,</span>
        <span class="n">initializers</span><span class="o">=</span><span class="n">initializers</span><span class="p">,</span> <span class="n">partitioners</span><span class="o">=</span><span class="n">partitioners</span><span class="p">,</span>
        <span class="n">regularizers</span><span class="o">=</span><span class="n">regularizers</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span>
        <span class="n">custom_getter</span><span class="o">=</span><span class="n">custom_getter</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

  <span class="c1"># Implements Transposable interface.</span>
<div class="viewcode-block" id="Conv3D.transpose"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.Conv3D.transpose">[docs]</a>  <span class="k">def</span> <span class="nf">transpose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns matching `Conv3DTranspose` module.</span>

<span class="sd">    Args:</span>
<span class="sd">      name: Optional string assigning name of transpose module. The default name</span>
<span class="sd">        is constructed by appending &quot;_transpose&quot; to `self.name`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      `Conv3DTranspose` module.</span>

<span class="sd">    Raises:</span>
<span class="sd">     base.NotSupportedError: If `rate` in any dimension &gt; 1.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rate</span><span class="p">):</span>
      <span class="k">raise</span> <span class="n">base</span><span class="o">.</span><span class="n">NotSupportedError</span><span class="p">(</span>
          <span class="s2">&quot;Cannot transpose a dilated convolution module.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">output_shape</span><span class="p">():</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span> <span class="o">==</span> <span class="n">DATA_FORMAT_NCDHW</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
      <span class="k">else</span><span class="p">:</span>  <span class="c1"># data_format == DATA_FORMAT_NDHWC</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_name</span> <span class="o">+</span> <span class="s2">&quot;_transpose&quot;</span>
    <span class="k">return</span> <span class="n">Conv3DTranspose</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span><span class="p">,</span>
                           <span class="n">output_shape</span><span class="o">=</span><span class="n">output_shape</span><span class="p">,</span>
                           <span class="n">kernel_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span><span class="p">,</span>
                           <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stride</span><span class="p">,</span>
                           <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_padding</span><span class="p">,</span>
                           <span class="n">use_bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_bias</span><span class="p">,</span>
                           <span class="n">initializers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">,</span>
                           <span class="n">partitioners</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span><span class="p">,</span>
                           <span class="n">regularizers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span><span class="p">,</span>
                           <span class="n">data_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">,</span>
                           <span class="n">custom_getter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_custom_getter</span><span class="p">,</span>
                           <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="Conv3DTranspose"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.Conv3DTranspose">[docs]</a><span class="k">class</span> <span class="nc">Conv3DTranspose</span><span class="p">(</span><span class="n">_ConvNDTranspose</span><span class="p">,</span> <span class="n">base</span><span class="o">.</span><span class="n">Transposable</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Volumetric transposed / reverse / up 3D convolution module, including bias.</span>

<span class="sd">  This acts as a light wrapper around the TensorFlow op `tf.nn.conv3d_transpose`</span>
<span class="sd">  abstracting away variable creation and sharing.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">SAME</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">initializers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">partitioners</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regularizers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">data_format</span><span class="o">=</span><span class="n">DATA_FORMAT_NDHWC</span><span class="p">,</span> <span class="n">custom_getter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv_3d_transpose&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a `Conv3DTranspose` module.</span>

<span class="sd">    See the following documentation for an explanation of VALID versus SAME</span>
<span class="sd">    padding modes:</span>
<span class="sd">    https://www.tensorflow.org/api_guides/python/nn#Convolution</span>

<span class="sd">    Args:</span>
<span class="sd">      output_channels: Number of output channels. `output_channels` can be</span>
<span class="sd">          either a number or a callable. In the latter case, since the function</span>
<span class="sd">          invocation is deferred to graph construction time, the user must only</span>
<span class="sd">          ensure `output_channels` can be called, returning an integer, when</span>
<span class="sd">          `build` is called.</span>
<span class="sd">      output_shape: Output shape of transpose convolution.</span>
<span class="sd">          Can be either an iterable of integers or a callable. In the latter</span>
<span class="sd">          case, since the function invocation is deferred to graph construction</span>
<span class="sd">          time, the user must only ensure that `output_shape` can be called,</span>
<span class="sd">          returning an iterable of format `(out_depth, out_height, out_width)`</span>
<span class="sd">          when `build` is called. Note that `output_shape` defines the size of</span>
<span class="sd">          output signal domain, as opposed to the shape of the output `Tensor`.</span>
<span class="sd">          If a None value is given, a default shape is automatically calculated</span>
<span class="sd">          (see docstring of _default_transpose_size function for more details).</span>
<span class="sd">      kernel_shape: Sequence of kernel sizes (of size 3), or integer that is</span>
<span class="sd">          used to define kernel size in all dimensions.</span>
<span class="sd">      stride: Sequence of kernel strides (of size 3), or integer that is used to</span>
<span class="sd">          define stride in all dimensions.</span>
<span class="sd">      padding: Padding algorithm, either `snt.SAME` or `snt.VALID`.</span>
<span class="sd">      use_bias: Whether to include bias parameters. Default `True`.</span>
<span class="sd">      initializers: Optional dict containing ops to initialize the filters (with</span>
<span class="sd">          key &#39;w&#39;) or biases (with key &#39;b&#39;).</span>
<span class="sd">      partitioners: Optional dict containing partitioners to partition</span>
<span class="sd">          weights (with key &#39;w&#39;) or biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          partitioners are used.</span>
<span class="sd">      regularizers: Optional dict containing regularizers for the filters</span>
<span class="sd">          (with key &#39;w&#39;) and the biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          regularizers are used. A regularizer should be a function that takes</span>
<span class="sd">          a single `Tensor` as an input and returns a scalar `Tensor` output,</span>
<span class="sd">          e.g. the L1 and L2 regularizers in `tf.contrib.layers`.</span>
<span class="sd">      data_format: A string. Specifies whether the channel dimension</span>
<span class="sd">          of the input and output is the last dimension (default, NDHWC), or the</span>
<span class="sd">          second dimension (NCDHW).</span>
<span class="sd">      custom_getter: Callable or dictionary of callables to use as</span>
<span class="sd">          custom getters inside the module. If a dictionary, the keys</span>
<span class="sd">          correspond to regexes to match variable names. See the</span>
<span class="sd">          `tf.get_variable` documentation for information about the</span>
<span class="sd">          custom_getter API.</span>
<span class="sd">      name: Name of the module.</span>

<span class="sd">    Raises:</span>
<span class="sd">      module.IncompatibleShapeError: If the given kernel shape is neither an</span>
<span class="sd">          integer nor a sequence of three integers.</span>
<span class="sd">      module.IncompatibleShapeError: If the given stride is neither an integer</span>
<span class="sd">          nor a sequence of three or five integers.</span>
<span class="sd">      ValueError: If the given padding is not `snt.VALID` or `snt.SAME`.</span>
<span class="sd">      ValueError: If the given kernel_shape is `None`.</span>
<span class="sd">      KeyError: If `initializers`, `partitioners` or `regularizers` contain any</span>
<span class="sd">          keys other than &#39;w&#39; or &#39;b&#39;.</span>
<span class="sd">      TypeError: If any of the given initializers, partitioners or regularizers</span>
<span class="sd">          are not callable.</span>
<span class="sd">      ValueError: If the passed-in data_format doesn&#39;t have a channel dimension.</span>
<span class="sd">      ValueError: If the given data_format is not a supported format (see</span>
<span class="sd">          `SUPPORTED_3D_DATA_FORMATS`).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">data_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">SUPPORTED_3D_DATA_FORMATS</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid data_format </span><span class="si">{:s}</span><span class="s2">. Allowed formats &quot;</span>
                       <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data_format</span><span class="p">,</span> <span class="n">SUPPORTED_3D_DATA_FORMATS</span><span class="p">))</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">Conv3DTranspose</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">output_channels</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="n">output_shape</span><span class="p">,</span>
        <span class="n">kernel_shape</span><span class="o">=</span><span class="n">kernel_shape</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
        <span class="n">use_bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">,</span> <span class="n">initializers</span><span class="o">=</span><span class="n">initializers</span><span class="p">,</span>
        <span class="n">partitioners</span><span class="o">=</span><span class="n">partitioners</span><span class="p">,</span> <span class="n">regularizers</span><span class="o">=</span><span class="n">regularizers</span><span class="p">,</span>
        <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span> <span class="n">custom_getter</span><span class="o">=</span><span class="n">custom_getter</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
    <span class="p">)</span>

  <span class="c1"># Implement Transposable interface</span>
<div class="viewcode-block" id="Conv3DTranspose.transpose"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.Conv3DTranspose.transpose">[docs]</a>  <span class="k">def</span> <span class="nf">transpose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns transposed Conv3DTranspose module, i.e. a Conv3D module.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_name</span> <span class="o">+</span> <span class="s2">&quot;_transpose&quot;</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span> <span class="o">==</span> <span class="n">DATA_FORMAT_NDHWC</span><span class="p">:</span>
      <span class="n">stride</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stride</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># self._data_format == DATA_FORMAT_NCDHW</span>
      <span class="n">stride</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stride</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>

    <span class="k">return</span> <span class="n">Conv3D</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_channels</span><span class="p">,</span>
                  <span class="n">kernel_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span><span class="p">,</span>
                  <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
                  <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_padding</span><span class="p">,</span>
                  <span class="n">use_bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_bias</span><span class="p">,</span>
                  <span class="n">initializers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">,</span>
                  <span class="n">partitioners</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span><span class="p">,</span>
                  <span class="n">regularizers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span><span class="p">,</span>
                  <span class="n">data_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">,</span>
                  <span class="n">custom_getter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_custom_getter</span><span class="p">,</span>
                  <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="InPlaneConv2D"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.InPlaneConv2D">[docs]</a><span class="k">class</span> <span class="nc">InPlaneConv2D</span><span class="p">(</span><span class="n">_ConvND</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Applies an in-plane convolution to each channel with tied filter weights.</span>

<span class="sd">  This acts as a light wrapper around the TensorFlow op</span>
<span class="sd">  `tf.nn.depthwise_conv2d`; it differs from the DepthWiseConv2D module in that</span>
<span class="sd">  it has tied weights (i.e. the same filter) for all the in-out channel pairs.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">SAME</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">initializers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">partitioners</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regularizers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">data_format</span><span class="o">=</span><span class="n">DATA_FORMAT_NHWC</span><span class="p">,</span> <span class="n">custom_getter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">name</span><span class="o">=</span><span class="s2">&quot;in_plane_conv2d&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs an InPlaneConv2D module.</span>

<span class="sd">    See the following documentation for an explanation of VALID versus SAME</span>
<span class="sd">    padding modes:</span>
<span class="sd">    https://www.tensorflow.org/api_guides/python/nn#Convolution</span>

<span class="sd">    Args:</span>
<span class="sd">      kernel_shape: Iterable with 2 elements in the layout [filter_height,</span>
<span class="sd">          filter_width]; or integer that is used to define the list in all</span>
<span class="sd">          dimensions.</span>
<span class="sd">      stride: Iterable with 2 or 4 elements of kernel strides, or integer that</span>
<span class="sd">          is used to define stride in all dimensions.</span>
<span class="sd">      padding: Padding algorithm, either `snt.SAME` or `snt.VALID`.</span>
<span class="sd">      use_bias: Whether to include bias parameters. Default `True`.</span>
<span class="sd">      initializers: Optional dict containing ops to initialize the filters (with</span>
<span class="sd">          key &#39;w&#39;) or biases (with key &#39;b&#39;).</span>
<span class="sd">      partitioners: Optional dict containing partitioners to partition the</span>
<span class="sd">          filters (with key &#39;w&#39;) or biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          partitioners are used.</span>
<span class="sd">      regularizers: Optional dict containing regularizers for the filters</span>
<span class="sd">          (with key &#39;w&#39;) and the biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          regularizers are used. A regularizer should be a function that takes</span>
<span class="sd">          a single `Tensor` as an input and returns a scalar `Tensor` output,</span>
<span class="sd">          e.g. the L1 and L2 regularizers in `tf.contrib.layers`.</span>
<span class="sd">      data_format: A string. Specifies whether the channel dimension</span>
<span class="sd">          of the input and output is the last dimension (default, NHWC), or the</span>
<span class="sd">          second dimension (NCHW).</span>
<span class="sd">      custom_getter: Callable or dictionary of callables to use as</span>
<span class="sd">          custom getters inside the module. If a dictionary, the keys</span>
<span class="sd">          correspond to regexes to match variable names. See the</span>
<span class="sd">          `tf.get_variable` documentation for information about the</span>
<span class="sd">          custom_getter API.</span>
<span class="sd">      name: Name of the module.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If the given data_format is not a supported format (see</span>
<span class="sd">          `SUPPORTED_2D_DATA_FORMATS`).</span>
<span class="sd">      base.IncompatibleShapeError: If the given kernel shape is not an integer;</span>
<span class="sd">          or if the given kernel shape is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given stride is not an integer; or if</span>
<span class="sd">          the given stride is not a sequence of two integers.</span>
<span class="sd">      ValueError: If the given padding is not `snt.VALID` or `snt.SAME`.</span>
<span class="sd">      KeyError: If `initializers`, `partitioners` or `regularizers` contain any</span>
<span class="sd">          keys other than &#39;w&#39; or &#39;b&#39;.</span>
<span class="sd">      TypeError: If any of the given initializers, partitioners or regularizers</span>
<span class="sd">          are not callable.</span>
<span class="sd">      ValueError: If the passed-in data_format doesn&#39;t have a channel dimension.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">data_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">SUPPORTED_2D_DATA_FORMATS</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid data_format </span><span class="si">{:s}</span><span class="s2">. Allowed formats &quot;</span>
                       <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data_format</span><span class="p">,</span> <span class="n">SUPPORTED_2D_DATA_FORMATS</span><span class="p">))</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">InPlaneConv2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">output_channels</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_channels</span><span class="p">,</span>
        <span class="n">kernel_shape</span><span class="o">=</span><span class="n">kernel_shape</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">,</span>
        <span class="n">initializers</span><span class="o">=</span><span class="n">initializers</span><span class="p">,</span> <span class="n">partitioners</span><span class="o">=</span><span class="n">partitioners</span><span class="p">,</span>
        <span class="n">regularizers</span><span class="o">=</span><span class="n">regularizers</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span>
        <span class="n">custom_getter</span><span class="o">=</span><span class="n">custom_getter</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_construct_w</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Construct the convolution weight matrix.</span>

<span class="sd">    Figures out the shape of the weight matrix, initialize it, and return it.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: A Tensor of shape `data_format` and of type `tf.float16`,</span>
<span class="sd">          `tf.bfloat16` or `tf.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      w: A weight matrix of the same type as `inputs` and of shape</span>
<span class="sd">        [kernel_shape, 1, 1].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">weight_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="s2">&quot;w&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">[</span><span class="s2">&quot;w&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">create_weight_initializer</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span>
                                                          <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">,</span>
                        <span class="n">shape</span><span class="o">=</span><span class="n">weight_shape</span><span class="p">,</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                        <span class="n">initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">[</span><span class="s2">&quot;w&quot;</span><span class="p">],</span>
                        <span class="n">partitioner</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                        <span class="n">regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">w</span>

  <span class="k">def</span> <span class="nf">_apply_conv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply a depthwise_conv2d operation on `inputs` using variable `w`.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: A Tensor of shape `data_format` and of type `tf.float16`,</span>
<span class="sd">          `tf.bfloat16` or `tf.float32`.</span>
<span class="sd">      w: A weight matrix of the same type as `inputs`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      outputs: The result of the convolution operation on `inputs`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tiled_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">depthwise_conv2d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                                     <span class="n">tiled_weights</span><span class="p">,</span>
                                     <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                     <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_padding</span><span class="p">,</span>
                                     <span class="n">data_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span></div>


<div class="viewcode-block" id="DepthwiseConv2D"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.DepthwiseConv2D">[docs]</a><span class="k">class</span> <span class="nc">DepthwiseConv2D</span><span class="p">(</span><span class="n">_ConvND</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Spatial depthwise 2D convolution module, including bias.</span>

<span class="sd">  This acts as a light wrapper around the TensorFlow ops</span>
<span class="sd">  `tf.nn.depthwise_conv2d`, abstracting away variable creation and sharing.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">channel_multiplier</span><span class="p">,</span>
               <span class="n">kernel_shape</span><span class="p">,</span>
               <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">padding</span><span class="o">=</span><span class="n">SAME</span><span class="p">,</span>
               <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">initializers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">partitioners</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">regularizers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">data_format</span><span class="o">=</span><span class="n">DATA_FORMAT_NHWC</span><span class="p">,</span>
               <span class="n">custom_getter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv_2d_depthwise&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a DepthwiseConv2D module.</span>

<span class="sd">    See the following documentation for an explanation of VALID versus SAME</span>
<span class="sd">    padding modes:</span>
<span class="sd">    https://www.tensorflow.org/api_guides/python/nn#Convolution</span>

<span class="sd">    Args:</span>
<span class="sd">      channel_multiplier: Number of channels to expand convolution to. Must be</span>
<span class="sd">          an integer. Must be &gt; 0. When `channel_multiplier` is set to 1, apply</span>
<span class="sd">          a different filter to each input channel producing one output channel</span>
<span class="sd">          per input channel. Numbers larger than 1 cause multiple different</span>
<span class="sd">          filters to be applied to each input channel, with their outputs being</span>
<span class="sd">          concatenated together, producing `channel_multiplier` *</span>
<span class="sd">          `input_channels` output channels.</span>
<span class="sd">      kernel_shape: Iterable with 2 elements in the following layout:</span>
<span class="sd">          [filter_height, filter_width] or integer that is</span>
<span class="sd">          used to define the list in all dimensions.</span>
<span class="sd">      stride: Iterable with 2 or 4 elements of kernel strides, or integer that</span>
<span class="sd">          is used to define stride in all dimensions. Layout of list:</span>
<span class="sd">          In case of 4 elements: `[1, stride_height, stride_widith, 1]`</span>
<span class="sd">          In case of 2 elements: `[stride_height, stride_width]`.</span>
<span class="sd">      padding: Padding algorithm, either `snt.SAME` or `snt.VALID`.</span>
<span class="sd">      use_bias: Whether to include bias parameters. Default `True`.</span>
<span class="sd">      initializers: Optional dict containing ops to initialize the filters (with</span>
<span class="sd">          key &#39;w&#39;) or biases (with key &#39;b&#39;).</span>
<span class="sd">      partitioners: Optional dict containing partitioners for the filters</span>
<span class="sd">          (with key &#39;w&#39;) and the biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          partitioners are used.</span>
<span class="sd">      regularizers: Optional dict containing regularizers for the filters</span>
<span class="sd">          (with key &#39;w&#39;) and the biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          regularizers are used. A regularizer should be a function that takes</span>
<span class="sd">          a single `Tensor` as an input and returns a scalar `Tensor` output,</span>
<span class="sd">          e.g. the L1 and L2 regularizers in `tf.contrib.layers`.</span>
<span class="sd">      data_format: A string. Specifies whether the channel dimension</span>
<span class="sd">          of the input and output is the last dimension (default, NHWC), or the</span>
<span class="sd">          second dimension (&quot;NCHW&quot;).</span>
<span class="sd">      custom_getter: Callable or dictionary of callables to use as</span>
<span class="sd">          custom getters inside the module. If a dictionary, the keys</span>
<span class="sd">          correspond to regexes to match variable names. See the</span>
<span class="sd">          `tf.get_variable` documentation for information about the</span>
<span class="sd">          custom_getter API.</span>
<span class="sd">      name: Name of the module.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If `channel_multiplier` isn&#39;t of type (`numbers.Integral` or</span>
<span class="sd">          `tf.Dimension`).</span>
<span class="sd">      ValueError: If `channel_multiplier` is less than 1.</span>
<span class="sd">      ValueError: If the given data_format is not a supported format (see</span>
<span class="sd">          `SUPPORTED_2D_DATA_FORMATS`).</span>
<span class="sd">      base.IncompatibleShapeError: If the given kernel shape is not an integer;</span>
<span class="sd">          or if the given kernel shape is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given stride is not an integer; or if</span>
<span class="sd">          the given stride is not a sequence of two integers.</span>
<span class="sd">      ValueError: If the given padding is not `snt.VALID` or `snt.SAME`.</span>
<span class="sd">      KeyError: If `initializers`, `partitioners` or `regularizers` contain any</span>
<span class="sd">          keys other than &#39;w&#39; or &#39;b&#39;.</span>
<span class="sd">      TypeError: If any of the given initializers, partitioners or regularizers</span>
<span class="sd">          are not callable.</span>
<span class="sd">      ValueError: If the passed-in data_format doesn&#39;t have a channel dimension.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">channel_multiplier</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span> <span class="ow">and</span>
        <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">channel_multiplier</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Dimension</span><span class="p">)):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">((</span><span class="s2">&quot;channel_multiplier (</span><span class="si">{}</span><span class="s2">), must be of type &quot;</span>
                        <span class="s2">&quot;(`tf.Dimension`, `numbers.Integral`).&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                            <span class="n">channel_multiplier</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">channel_multiplier</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;channel_multiplier (</span><span class="si">{}</span><span class="s2">), must be &gt;= 1&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
          <span class="n">channel_multiplier</span><span class="p">))</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_channel_multiplier</span> <span class="o">=</span> <span class="n">channel_multiplier</span>

    <span class="k">if</span> <span class="n">data_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">SUPPORTED_2D_DATA_FORMATS</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid data_format </span><span class="si">{:s}</span><span class="s2">. Allowed formats &quot;</span>
                       <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data_format</span><span class="p">,</span> <span class="n">SUPPORTED_2D_DATA_FORMATS</span><span class="p">))</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">DepthwiseConv2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">output_channels</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_channel_multiplier</span><span class="p">,</span>
        <span class="n">kernel_shape</span><span class="o">=</span><span class="n">kernel_shape</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">,</span>
        <span class="n">initializers</span><span class="o">=</span><span class="n">initializers</span><span class="p">,</span> <span class="n">partitioners</span><span class="o">=</span><span class="n">partitioners</span><span class="p">,</span>
        <span class="n">regularizers</span><span class="o">=</span><span class="n">regularizers</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span>
        <span class="n">custom_getter</span><span class="o">=</span><span class="n">custom_getter</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_construct_w</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Construct the convolution weight matrix.</span>

<span class="sd">    Figures out the shape of the weight matrix, initializes it, and returns it.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: A Tensor of shape `data_format` and of type `tf.float16`,</span>
<span class="sd">          `tf.bfloat16` or `tf.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      w: A weight matrix of the same type as `inputs` and of shape</span>
<span class="sd">        [kernel_sizes, input_channels, channel_multiplier].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># For depthwise conv, output_channels = in_channels * channel_multiplier.</span>
    <span class="c1"># By default, depthwise conv applies a different filter to every input</span>
    <span class="c1"># channel. If channel_multiplier &gt; 1, one input channel is used to produce</span>
    <span class="c1"># `channel_multiplier` outputs, which are then concatenated together.</span>
    <span class="c1"># This results in:</span>
    <span class="n">weight_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span><span class="p">,</span>
                                         <span class="bp">self</span><span class="o">.</span><span class="n">_channel_multiplier</span><span class="p">)</span>

    <span class="k">if</span> <span class="s2">&quot;w&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">[</span><span class="s2">&quot;w&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">create_weight_initializer</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span>
                                                          <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">,</span>
                        <span class="n">shape</span><span class="o">=</span><span class="n">weight_shape</span><span class="p">,</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                        <span class="n">initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">[</span><span class="s2">&quot;w&quot;</span><span class="p">],</span>
                        <span class="n">partitioner</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                        <span class="n">regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">w</span>

  <span class="k">def</span> <span class="nf">_apply_conv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply a depthwise_conv2d operation on `inputs` using variable `w`.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: A Tensor of shape `data_format` and of type `tf.float16`,</span>
<span class="sd">          `tf.bfloat16` or `tf.float32`.</span>
<span class="sd">      w: A weight matrix of the same type as `inputs`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      outputs: The result of the convolution operation on `inputs`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">depthwise_conv2d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                                     <span class="n">w</span><span class="p">,</span>
                                     <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                     <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_padding</span><span class="p">,</span>
                                     <span class="n">data_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">channel_multiplier</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the channel multiplier argument.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_channel_multiplier</span></div>


<div class="viewcode-block" id="SeparableConv2D"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.SeparableConv2D">[docs]</a><span class="k">class</span> <span class="nc">SeparableConv2D</span><span class="p">(</span><span class="n">_ConvND</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Performs an in-plane convolution to each channel independently.</span>

<span class="sd">  This acts as a light wrapper around the TensorFlow op</span>
<span class="sd">  `tf.nn.separable_conv2d`, abstracting away variable creation and sharing.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">output_channels</span><span class="p">,</span>
               <span class="n">channel_multiplier</span><span class="p">,</span>
               <span class="n">kernel_shape</span><span class="p">,</span>
               <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">padding</span><span class="o">=</span><span class="n">SAME</span><span class="p">,</span>
               <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">initializers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">partitioners</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">regularizers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">data_format</span><span class="o">=</span><span class="n">DATA_FORMAT_NHWC</span><span class="p">,</span>
               <span class="n">custom_getter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">name</span><span class="o">=</span><span class="s2">&quot;separable_conv2d&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a SeparableConv2D module.</span>

<span class="sd">    See the following documentation for an explanation of VALID versus SAME</span>
<span class="sd">    padding modes:</span>
<span class="sd">    https://www.tensorflow.org/api_guides/python/nn#Convolution</span>

<span class="sd">    Args:</span>
<span class="sd">      output_channels: Number of output channels. Must be an integer.</span>
<span class="sd">      channel_multiplier: Number of channels to expand pointwise (depthwise)</span>
<span class="sd">          convolution to. Must be an integer. Must be &gt; 0.</span>
<span class="sd">          When `channel_multiplier` is set to 1, applies a different filter to</span>
<span class="sd">          each input channel. Numbers larger than 1 cause the filter to be</span>
<span class="sd">          applied to `channel_multiplier` input channels. Outputs are</span>
<span class="sd">          concatenated together.</span>
<span class="sd">      kernel_shape: List with 2 elements in the following layout:</span>
<span class="sd">          [filter_height, filter_width] or integer that is</span>
<span class="sd">          used to define the list in all dimensions.</span>
<span class="sd">      stride: List with 4 elements of kernel strides, or integer that is used to</span>
<span class="sd">          define stride in all dimensions. Layout of list:</span>
<span class="sd">          [1, stride_y, stride_x, 1].</span>
<span class="sd">      padding: Padding algorithm, either `snt.SAME` or `snt.VALID`.</span>
<span class="sd">      use_bias: Whether to include bias parameters. Default `True`.</span>
<span class="sd">      initializers: Optional dict containing ops to initialize the filters (with</span>
<span class="sd">          keys &#39;w_dw&#39; for depthwise and &#39;w_pw&#39; for pointwise) or biases</span>
<span class="sd">          (with key &#39;b&#39;).</span>
<span class="sd">      partitioners: Optional dict containing partitioners to partition the</span>
<span class="sd">          filters (with key &#39;w&#39;) or biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          partitioners are used.</span>
<span class="sd">      regularizers: Optional dict containing regularizers for the filters</span>
<span class="sd">          (with keys &#39;w_dw&#39; for depthwise and &#39;w_pw&#39; for pointwise) and the</span>
<span class="sd">          biases (with key &#39;b&#39;). As a default, no regularizers are used.</span>
<span class="sd">          A regularizer should be a function that takes a single `Tensor` as an</span>
<span class="sd">          input and returns a scalar `Tensor` output, e.g. the L1 and L2</span>
<span class="sd">          regularizers in `tf.contrib.layers`.</span>
<span class="sd">      data_format: A string. Specifies whether the channel dimension</span>
<span class="sd">          of the input and output is the last dimension (default, NHWC), or the</span>
<span class="sd">          second dimension (&quot;NCHW&quot;).</span>
<span class="sd">      custom_getter: Callable or dictionary of callables to use as</span>
<span class="sd">          custom getters inside the module. If a dictionary, the keys</span>
<span class="sd">          correspond to regexes to match variable names. See the</span>
<span class="sd">          `tf.get_variable` documentation for information about the</span>
<span class="sd">          custom_getter API.</span>
<span class="sd">      name: Name of the module.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If `channel_multiplier` isn&#39;t of type (`numbers.Integral` or</span>
<span class="sd">          `tf.Dimension`).</span>
<span class="sd">      ValueError: If `channel_multiplier` is less than 1.</span>
<span class="sd">      ValueError: If the given data_format is not a supported format (see</span>
<span class="sd">          `SUPPORTED_2D_DATA_FORMATS`).</span>
<span class="sd">      base.IncompatibleShapeError: If the given kernel shape is not an integer;</span>
<span class="sd">          or if the given kernel shape is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given stride is not an integer; or if</span>
<span class="sd">          the given stride is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given rate is not an integer; or if</span>
<span class="sd">          the given rate is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If a mask is a TensorFlow Tensor with</span>
<span class="sd">          a not fully defined shape.</span>
<span class="sd">      base.NotSupportedError: If rate in any dimension and the stride in any</span>
<span class="sd">          dimension are simultaneously &gt; 1.</span>
<span class="sd">      ValueError: If the given padding is not `snt.VALID` or `snt.SAME`.</span>
<span class="sd">      KeyError: If `initializers`, `partitioners` or `regularizers` contain any</span>
<span class="sd">          keys other than &#39;w_dw&#39;, &#39;w_pw&#39; or &#39;b&#39;.</span>
<span class="sd">      TypeError: If any of the given initializers, partitioners or regularizers</span>
<span class="sd">          are not callable.</span>
<span class="sd">      TypeError: If mask is given and it is not convertible to a Tensor.</span>
<span class="sd">      ValueError: If the passed-in data_format doesn&#39;t have a channel dimension.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">channel_multiplier</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span> <span class="ow">and</span>
        <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">channel_multiplier</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Dimension</span><span class="p">)):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">((</span><span class="s2">&quot;channel_multiplier (</span><span class="si">{}</span><span class="s2">), must be of type &quot;</span>
                        <span class="s2">&quot;(`tf.Dimension`, `numbers.Integral`).&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                            <span class="n">channel_multiplier</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">channel_multiplier</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;channel_multiplier (</span><span class="si">{}</span><span class="s2">), must be &gt;= 1&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
          <span class="n">channel_multiplier</span><span class="p">))</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_channel_multiplier</span> <span class="o">=</span> <span class="n">channel_multiplier</span>

    <span class="k">if</span> <span class="n">data_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">SUPPORTED_2D_DATA_FORMATS</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid data_format </span><span class="si">{:s}</span><span class="s2">. Allowed formats &quot;</span>
                       <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data_format</span><span class="p">,</span> <span class="n">SUPPORTED_2D_DATA_FORMATS</span><span class="p">))</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">SeparableConv2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">output_channels</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span>
        <span class="n">kernel_shape</span><span class="o">=</span><span class="n">kernel_shape</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">,</span>
        <span class="n">initializers</span><span class="o">=</span><span class="n">initializers</span><span class="p">,</span> <span class="n">partitioners</span><span class="o">=</span><span class="n">partitioners</span><span class="p">,</span>
        <span class="n">regularizers</span><span class="o">=</span><span class="n">regularizers</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span>
        <span class="n">custom_getter</span><span class="o">=</span><span class="n">custom_getter</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

<div class="viewcode-block" id="SeparableConv2D.get_possible_initializer_keys"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.SeparableConv2D.get_possible_initializer_keys">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">get_possible_initializer_keys</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;w_dw&quot;</span><span class="p">,</span> <span class="s2">&quot;w_pw&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">}</span> <span class="k">if</span> <span class="n">use_bias</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;w_dw&quot;</span><span class="p">,</span> <span class="s2">&quot;w_pw&quot;</span><span class="p">}</span></div>

  <span class="k">def</span> <span class="nf">_construct_w</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Connects the module into the graph, with input Tensor `inputs`.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: A 4D Tensor of shape:</span>
<span class="sd">          [batch_size, input_height, input_width, input_channels]</span>
<span class="sd">          and of type `tf.float16`, `tf.bfloat16` or `tf.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple of two 4D Tensors, each with the same dtype as `inputs`:</span>
<span class="sd">        1. w_dw, the depthwise weight matrix, of shape:</span>
<span class="sd">          [kernel_size, input_channels, channel_multiplier]</span>
<span class="sd">        2. w_pw, the pointwise weight matrix, of shape:</span>
<span class="sd">          [1, 1, channel_multiplier * input_channels, output_channels].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">depthwise_weight_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span><span class="p">,</span>
                                                   <span class="bp">self</span><span class="o">.</span><span class="n">_channel_multiplier</span><span class="p">)</span>
    <span class="n">pointwise_input_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_channel_multiplier</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span>
    <span class="n">pointwise_weight_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">pointwise_input_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span><span class="p">)</span>

    <span class="k">if</span> <span class="s2">&quot;w_dw&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">:</span>
      <span class="n">fan_in_shape</span> <span class="o">=</span> <span class="n">depthwise_weight_shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">[</span><span class="s2">&quot;w_dw&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">create_weight_initializer</span><span class="p">(</span><span class="n">fan_in_shape</span><span class="p">,</span>
                                                             <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="s2">&quot;w_pw&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">:</span>
      <span class="n">fan_in_shape</span> <span class="o">=</span> <span class="n">pointwise_weight_shape</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">[</span><span class="s2">&quot;w_pw&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">create_weight_initializer</span><span class="p">(</span><span class="n">fan_in_shape</span><span class="p">,</span>
                                                             <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="n">w_dw</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
        <span class="s2">&quot;w_dw&quot;</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">depthwise_weight_shape</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">[</span><span class="s2">&quot;w_dw&quot;</span><span class="p">],</span>
        <span class="n">partitioner</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;w_dw&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="n">regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;w_dw&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>

    <span class="n">w_pw</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
        <span class="s2">&quot;w_pw&quot;</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">pointwise_weight_shape</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">[</span><span class="s2">&quot;w_pw&quot;</span><span class="p">],</span>
        <span class="n">partitioner</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;w_pw&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="n">regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;w_pw&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">w_dw</span><span class="p">,</span> <span class="n">w_pw</span>

  <span class="k">def</span> <span class="nf">_apply_conv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply a `separable_conv2d` operation on `inputs` using `w`.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: A Tensor of shape `data_format` and of type `tf.float16`,</span>
<span class="sd">          `tf.bfloat16` or `tf.float32`.</span>
<span class="sd">      w: A tuple of weight matrices of the same type as `inputs`, the first</span>
<span class="sd">        being the depthwise weight matrix, and the second being the pointwise</span>
<span class="sd">        weight matrix.</span>

<span class="sd">    Returns:</span>
<span class="sd">      outputs: The result of the convolution operation on `inputs`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">w_dw</span><span class="p">,</span> <span class="n">w_pw</span> <span class="o">=</span> <span class="n">w</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">separable_conv2d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                                     <span class="n">w_dw</span><span class="p">,</span>
                                     <span class="n">w_pw</span><span class="p">,</span>
                                     <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                     <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_padding</span><span class="p">,</span>
                                     <span class="n">data_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">channel_multiplier</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the channel multiplier argument.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_channel_multiplier</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">w_dw</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the Variable containing the depthwise weight matrix.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_is_connected</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">w_pw</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the Variable containing the pointwise weight matrix.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_is_connected</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span></div>


<div class="viewcode-block" id="SeparableConv1D"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.SeparableConv1D">[docs]</a><span class="k">class</span> <span class="nc">SeparableConv1D</span><span class="p">(</span><span class="n">_ConvND</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Performs an in-plane convolution to each channel independently.</span>

<span class="sd">  This acts as a light wrapper around the TensorFlow op</span>
<span class="sd">  `tf.nn.separable_conv2d`, abstracting away variable creation and sharing.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">output_channels</span><span class="p">,</span>
               <span class="n">channel_multiplier</span><span class="p">,</span>
               <span class="n">kernel_shape</span><span class="p">,</span>
               <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">padding</span><span class="o">=</span><span class="n">SAME</span><span class="p">,</span>
               <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">initializers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">partitioners</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">regularizers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">data_format</span><span class="o">=</span><span class="n">DATA_FORMAT_NWC</span><span class="p">,</span>
               <span class="n">custom_getter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">name</span><span class="o">=</span><span class="s2">&quot;separable_conv1d&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a SeparableConv1D module.</span>

<span class="sd">    See the following documentation for an explanation of VALID versus SAME</span>
<span class="sd">    padding modes:</span>
<span class="sd">    https://www.tensorflow.org/api_guides/python/nn#Convolution</span>

<span class="sd">    Args:</span>
<span class="sd">      output_channels: Number of output channels. Must be an integer.</span>
<span class="sd">      channel_multiplier: Number of channels to expand pointwise (depthwise)</span>
<span class="sd">          convolution to. Must be an integer. Must be &gt; 0.</span>
<span class="sd">          When `channel_multiplier` is set to 1, applies a different filter to</span>
<span class="sd">          each input channel. Numbers larger than 1 cause the filter to be</span>
<span class="sd">          applied to `channel_multiplier` input channels. Outputs are</span>
<span class="sd">          concatenated together.</span>
<span class="sd">      kernel_shape: List with 2 elements in the following layout:</span>
<span class="sd">          [filter_height, filter_width] or integer that is</span>
<span class="sd">          used to define the list in all dimensions.</span>
<span class="sd">      stride: List with 4 elements of kernel strides, or integer that is used to</span>
<span class="sd">          define stride in all dimensions. Layout of list:</span>
<span class="sd">          [1, stride_y, stride_x, 1].</span>
<span class="sd">      padding: Padding algorithm, either `snt.SAME` or `snt.VALID`.</span>
<span class="sd">      use_bias: Whether to include bias parameters. Default `True`.</span>
<span class="sd">      initializers: Optional dict containing ops to initialize the filters (with</span>
<span class="sd">          keys &#39;w_dw&#39; for depthwise and &#39;w_pw&#39; for pointwise) or biases</span>
<span class="sd">          (with key &#39;b&#39;).</span>
<span class="sd">      partitioners: Optional dict containing partitioners to partition the</span>
<span class="sd">          filters (with key &#39;w&#39;) or biases (with key &#39;b&#39;). As a default, no</span>
<span class="sd">          partitioners are used.</span>
<span class="sd">      regularizers: Optional dict containing regularizers for the filters</span>
<span class="sd">          (with keys &#39;w_dw&#39; for depthwise and &#39;w_pw&#39; for pointwise) and the</span>
<span class="sd">          biases (with key &#39;b&#39;). As a default, no regularizers are used.</span>
<span class="sd">          A regularizer should be a function that takes a single `Tensor` as an</span>
<span class="sd">          input and returns a scalar `Tensor` output, e.g. the L1 and L2</span>
<span class="sd">          regularizers in `tf.contrib.layers`.</span>
<span class="sd">      data_format: A string. Specifies whether the channel dimension</span>
<span class="sd">          of the input and output is the last dimension (default, NWC), or the</span>
<span class="sd">          second dimension (&quot;NCW&quot;).</span>
<span class="sd">      custom_getter: Callable or dictionary of callables to use as</span>
<span class="sd">          custom getters inside the module. If a dictionary, the keys</span>
<span class="sd">          correspond to regexes to match variable names. See the</span>
<span class="sd">          `tf.get_variable` documentation for information about the</span>
<span class="sd">          custom_getter API.</span>
<span class="sd">      name: Name of the module.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If `channel_multiplier` isn&#39;t of type (`numbers.Integral` or</span>
<span class="sd">          `tf.Dimension`).</span>
<span class="sd">      ValueError: If `channel_multiplier` is less than 1.</span>
<span class="sd">      ValueError: If the given data_format is not a supported format (see</span>
<span class="sd">          `SUPPORTED_1D_DATA_FORMATS`).</span>
<span class="sd">      base.IncompatibleShapeError: If the given kernel shape is not an integer;</span>
<span class="sd">          or if the given kernel shape is not a sequence of one integer.</span>
<span class="sd">      base.IncompatibleShapeError: If the given stride is not an integer; or if</span>
<span class="sd">          the given stride is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If the given rate is not an integer; or if</span>
<span class="sd">          the given rate is not a sequence of two integers.</span>
<span class="sd">      base.IncompatibleShapeError: If a mask is a TensorFlow Tensor with</span>
<span class="sd">          a not fully defined shape.</span>
<span class="sd">      base.NotSupportedError: If rate in any dimension and the stride in any</span>
<span class="sd">          dimension are simultaneously &gt; 1.</span>
<span class="sd">      ValueError: If the given padding is not `snt.VALID` or `snt.SAME`.</span>
<span class="sd">      KeyError: If `initializers`, `partitioners` or `regularizers` contain any</span>
<span class="sd">          keys other than &#39;w_dw&#39;, &#39;w_pw&#39; or &#39;b&#39;.</span>
<span class="sd">      TypeError: If any of the given initializers, partitioners or regularizers</span>
<span class="sd">          are not callable.</span>
<span class="sd">      TypeError: If mask is given and it is not convertible to a Tensor.</span>
<span class="sd">      ValueError: If the passed-in data_format doesn&#39;t have a channel dimension.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">channel_multiplier</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span> <span class="ow">and</span>
        <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">channel_multiplier</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Dimension</span><span class="p">)):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">((</span><span class="s2">&quot;channel_multiplier (</span><span class="si">{}</span><span class="s2">), must be of type &quot;</span>
                        <span class="s2">&quot;(`tf.Dimension`, `numbers.Integral`).&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                            <span class="n">channel_multiplier</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">channel_multiplier</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;channel_multiplier (</span><span class="si">{}</span><span class="s2">), must be &gt;= 1&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
          <span class="n">channel_multiplier</span><span class="p">))</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_channel_multiplier</span> <span class="o">=</span> <span class="n">channel_multiplier</span>

    <span class="k">if</span> <span class="n">data_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">SUPPORTED_1D_DATA_FORMATS</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid data_format </span><span class="si">{:s}</span><span class="s2">. Allowed formats &quot;</span>
                       <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data_format</span><span class="p">,</span> <span class="n">SUPPORTED_1D_DATA_FORMATS</span><span class="p">))</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">SeparableConv1D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">output_channels</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span>
        <span class="n">kernel_shape</span><span class="o">=</span><span class="n">kernel_shape</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">,</span>
        <span class="n">initializers</span><span class="o">=</span><span class="n">initializers</span><span class="p">,</span> <span class="n">partitioners</span><span class="o">=</span><span class="n">partitioners</span><span class="p">,</span>
        <span class="n">regularizers</span><span class="o">=</span><span class="n">regularizers</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span>
        <span class="n">custom_getter</span><span class="o">=</span><span class="n">custom_getter</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

<div class="viewcode-block" id="SeparableConv1D.get_possible_initializer_keys"><a class="viewcode-back" href="../../../../api/sonnet.python.modules.html#sonnet.python.modules.conv.SeparableConv1D.get_possible_initializer_keys">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">get_possible_initializer_keys</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;w_dw&quot;</span><span class="p">,</span> <span class="s2">&quot;w_pw&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">}</span> <span class="k">if</span> <span class="n">use_bias</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;w_dw&quot;</span><span class="p">,</span> <span class="s2">&quot;w_pw&quot;</span><span class="p">}</span></div>

  <span class="k">def</span> <span class="nf">_construct_w</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Connects the module into the graph, with input Tensor `inputs`.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: A 4D Tensor of shape:</span>
<span class="sd">          [batch_size, input_height, input_width, input_channels]</span>
<span class="sd">          and of type `tf.float16`, `tf.bfloat16` or `tf.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple of two 4D Tensors, each with the same dtype as `inputs`:</span>
<span class="sd">        1. w_dw, the depthwise weight matrix, of shape:</span>
<span class="sd">          [kernel_size, input_channels, channel_multiplier]</span>
<span class="sd">        2. w_pw, the pointwise weight matrix, of shape:</span>
<span class="sd">          [1, 1, channel_multiplier * input_channels, output_channels].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">depthwise_weight_shape</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_kernel_shape</span> <span class="o">+</span>
                              <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_channel_multiplier</span><span class="p">))</span>
    <span class="n">pointwise_input_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_channel_multiplier</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span>
    <span class="n">pointwise_weight_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">pointwise_input_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span><span class="p">)</span>

    <span class="k">if</span> <span class="s2">&quot;w_dw&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">:</span>
      <span class="n">fan_in_shape</span> <span class="o">=</span> <span class="n">depthwise_weight_shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">[</span><span class="s2">&quot;w_dw&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">create_weight_initializer</span><span class="p">(</span><span class="n">fan_in_shape</span><span class="p">,</span>
                                                             <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="s2">&quot;w_pw&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">:</span>
      <span class="n">fan_in_shape</span> <span class="o">=</span> <span class="n">pointwise_weight_shape</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">[</span><span class="s2">&quot;w_pw&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">create_weight_initializer</span><span class="p">(</span><span class="n">fan_in_shape</span><span class="p">,</span>
                                                             <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="n">w_dw</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
        <span class="s2">&quot;w_dw&quot;</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">depthwise_weight_shape</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">[</span><span class="s2">&quot;w_dw&quot;</span><span class="p">],</span>
        <span class="n">partitioner</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;w_dw&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="n">regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;w_dw&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>

    <span class="n">w_pw</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
        <span class="s2">&quot;w_pw&quot;</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">pointwise_weight_shape</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_initializers</span><span class="p">[</span><span class="s2">&quot;w_pw&quot;</span><span class="p">],</span>
        <span class="n">partitioner</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_partitioners</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;w_pw&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="n">regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;w_pw&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">w_dw</span><span class="p">,</span> <span class="n">w_pw</span>

  <span class="k">def</span> <span class="nf">_apply_conv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply a `separable_conv2d` operation on `inputs` using `w`.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: A Tensor of shape `data_format` and of type `tf.float16`,</span>
<span class="sd">          `tf.bfloat16` or `tf.float32`.</span>
<span class="sd">      w: A tuple of weight matrices of the same type as `inputs`, the first</span>
<span class="sd">        being the depthwise weight matrix, and the second being the pointwise</span>
<span class="sd">        weight matrix.</span>

<span class="sd">    Returns:</span>
<span class="sd">      outputs: The result of the convolution operation on `inputs`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_format</span> <span class="o">==</span> <span class="n">DATA_FORMAT_NWC</span><span class="p">:</span>
      <span class="n">h_dim</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="n">two_dim_conv_data_format</span> <span class="o">=</span> <span class="n">DATA_FORMAT_NHWC</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">h_dim</span> <span class="o">=</span> <span class="mi">2</span>
      <span class="n">two_dim_conv_data_format</span> <span class="o">=</span> <span class="n">DATA_FORMAT_NCHW</span>

    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">h_dim</span><span class="p">)</span>
    <span class="n">two_dim_conv_stride</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">[:</span><span class="n">h_dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">[</span><span class="n">h_dim</span><span class="p">:]</span>

    <span class="n">w_dw</span><span class="p">,</span> <span class="n">w_pw</span> <span class="o">=</span> <span class="n">w</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">separable_conv2d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                                     <span class="n">w_dw</span><span class="p">,</span>
                                     <span class="n">w_pw</span><span class="p">,</span>
                                     <span class="n">strides</span><span class="o">=</span><span class="n">two_dim_conv_stride</span><span class="p">,</span>
                                     <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_padding</span><span class="p">,</span>
                                     <span class="n">data_format</span><span class="o">=</span><span class="n">two_dim_conv_data_format</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="p">[</span><span class="n">h_dim</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">outputs</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">channel_multiplier</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the channel multiplier argument.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_channel_multiplier</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">w_dw</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the Variable containing the depthwise weight matrix.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_is_connected</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">w_pw</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the Variable containing the pointwise weight matrix.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_is_connected</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span></div>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../index.html">sonnet</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../index.html">Documentation overview</a><ul>
  <li><a href="../../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Sonnet Authors.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.7.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.11</a>
      
    </div>

    

    
  </body>
</html>